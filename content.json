{"meta":{"title":"y0c","subtitle":null,"description":"hosung dev log","author":"hosung","url":"https://y0c.github.io"},"pages":[],"posts":[{"title":"GraphQL Data Mocking","slug":"graphql-data-mocking","date":"2019-11-17T09:53:14.000Z","updated":"2019-11-17T14:20:46.711Z","comments":true,"path":"2019/11/17/graphql-data-mocking/","link":"","permalink":"https://y0c.github.io/2019/11/17/graphql-data-mocking/","excerpt":"","text":"이번 포스팅에서는 GraphQL을 사용할때 Data를 Mocking하는 방법에 대해서 소개해보려고 한다. MockingMocking은 주로 테스팅에서 많이 사용되는 용어이다. Unit Test를 작성할때 테스트하기 어려운 상황에서 행위검증을 위해 주로 사용된다. 자세하게 표현하면 stub, spy와 같은 용어들이 있지만 여기서는 가짜 데이터를 만들어내는 행위를 Data에 대한 Mocking이라고 표현하겠다. Data Mocking?웹개발은 Frontend, Backend 로 파트가 나뉘어져 파트별 개발자들의 협력으로 개발하는 경우가 많다.이런식으로 나뉘어져 개발할 경우 Frontend 개발자의 작업은 Backend Data에 의존적이다. API 호출을 통해서 받아온 데이터를 통해 UI가 그려지는 경우가 대부분이기 때문이다.이렇게 파트별 Task간의 의존성의 있는경우 병렬적으로 개발하지 못해서 생산성이 저하되는 단점이 있다. 이러한 이유로 API가 개발 완료되지 않은 상황이라면 Frontend 개발시 자체적으로 API 호출하는 부분을 분리하고 Mocking해서 사용하거나 Fake Data를 import 해서 진행하기도 한다. 간단한 예시를 보자. 아래 코드는 TodoList를 만든다고 가정하고 작성하는 코드이다.123456789101112131415161718192021import React from 'react'// fake data importimport todos from './fixture/todos'// or API call// import getTodos from './api/todo'const TodoList = (&#123; todos &#125;) =&gt; ( &lt;ul&gt; &#123; todos.map(&#123; id, title, completed &#125; =&gt; (&#123; &lt;li key=&#123;id&#125;&gt;&#123;title&#125;&lt;/li&gt; &#125;)) &#125; &lt;/ul&gt;)const App = () =&gt; ( &lt;div&gt; &lt;TodoList todos=&#123;todos&#125; /&gt; &lt;/div&gt;) 위 코드를 보면 fixture 디렉토리에 Fake Data를 미리 정의해놓고 UI를 확인하거나 API call하는 부분을 분리해서 test시에는 Fake Data를 반환하는 promise로 작성해놓고 사용할 수 있다. 이렇게 Frontend에서 Data를 mocking해서 개발할 경우 실제 API가 개발되면 대부분 코드가 변경되고 다시 테스트해야되는 상황이 생길 수 있다. GraphQL Data MockingFrontend와 Backend가 병렬적으로 작업할때 좀 더 매끄럽게 진행하는 방법은 없을까?GraphQL 을 사용하면 Type System을 활용해서 손 쉽게 Data Mocking하는 기능을 사용할 수 있다.(GraphQL 구현체마다 지원할수도 안할수도 있다.) 간단한 예제를 만들면서 GraphQL Mocking이 어떤식으로 작동하는지 살펴보도록 하자. TodoList SDL1234567891011type Todo &#123; id: Int! title: String! completed: Boolean! createdAt: String! updatedAt: String!&#125;type Query &#123; todos: [Todo]!&#125; 위와 같이 GraphQL 은 SDL상에 Type이 명시되어 있다.Mock Data를 만들때 이 Type을 이용해서 쉽게 DataSet을 구성할 수 있다.GraphQL Data Mocking이 편리한 이유이기도 하다. Type에 대한 Mock Resolver를 만드는 예시이다.12345&#123; Int :() =&gt; faker.random.number(100), String :() =&gt; faker.random.word(), Boolean :() =&gt; faker.random.boolean(),&#125; 이렇게 Query나 Field에 대한 Resolver가 아닌 Type에 Resolver를 붙여서 사용이 가능하다.Int, String, Boolean Type으로 명시되어 있는 field는 모두 해당 resolver에 의해서 data가 만들어지게된다.ex) id - 1 ~ 100 난수 title - random word … 이건 GraphQL에 있는 기본 Scalar에 대해서만 작성했는데 Custom Type에 대해서도 설정이 가능하고 자유도 높게 사용이 가능하다.1234Todo: () =&gt; (&#123; createdAt:() =&gt; new Date().toDateString(), updatedAt:() =&gt; new Date().toDateString()&#125;), 위와 같이 특정 Type, Field에 대해서만 다른 resolver를 지정할 수도 있다.(Custom Date Scalar를 만들고 Date에 Resolver사용도 가능하다. 이 예제에서는 편의상 간단하게 작성했다.) List Type의 경우에는 MockList 를 이용할 수 있다.아래 코드는 todos Query가 몇개의 데이터를 리턴할지 결정하는 부분이다.1234Query: () =&gt; (&#123; todos: new MockList(20) // or range new MockList([1, 20])&#125;) 아래 코드는 동작하는 예제의 전체 코드이다.FULL CODE12345678910111213141516171819202122232425262728293031323334353637383940const &#123; makeExecutableSchema, addMockFunctionsToSchema, MockList &#125; = require('graphql-tools')const faker = require('faker')const &#123; ApolloServer &#125; = require('apollo-server')const typeDefs = ` type Todo &#123; id: Int! title: String! completed: Boolean! createdAt: String! updatedAt: String! &#125; type Query &#123; todos: [Todo]! &#125;`const mocks = &#123; Int :() =&gt; faker.random.number(100), String :() =&gt; faker.random.word(), Boolean :() =&gt; faker.random.boolean(), Todo: () =&gt; (&#123; createdAt:() =&gt; new Date().toDateString(), updatedAt:() =&gt; new Date().toDateString() &#125;), Query: () =&gt; (&#123; todos: () =&gt; new MockList(100) &#125;)&#125;const schema = makeExecutableSchema(&#123; typeDefs&#125;)addMockFunctionsToSchema(&#123; schema, mocks, preserveResolvers: true &#125;)const server = new ApolloServer(&#123; schema, mocks &#125;)server.listen(3000) Result Dataset 예시12345678910111213141516171819202122232425262728293031323334353637&#123; \"data\": &#123; \"todos\": [ &#123; \"id\": 18, \"title\": \"Bedfordshire\", \"completed\": true, \"createdAt\": \"Sun Nov 17 2019\" &#125;, &#123; \"id\": 92, \"title\": \"payment\", \"completed\": false, \"createdAt\": \"Sun Nov 17 2019\" &#125;, &#123; \"id\": 5, \"title\": \"National\", \"completed\": true, \"createdAt\": \"Sun Nov 17 2019\" &#125;, &#123; \"id\": 5, \"title\": \"Plastic\", \"completed\": false, \"createdAt\": \"Sun Nov 17 2019\" &#125;, &#123; \"id\": 6, \"title\": \"Devolved\", \"completed\": true, \"createdAt\": \"Sun Nov 17 2019\" &#125;, ... ] &#125;&#125; 기존에 Apollo Server가 구성되어 있다면 schema는 이미 있는 상태이고 여기에 mocks와 addMockFunctionsToSchema 만 작성해주면 된다. GraphQL은 BaseType과 이를 조합한 Type들로 구성되어 있다.즉 몇가지 타입들에 대한 Mock Resolver를 구현해놓으면 더 이상 Dataset을 만드는데 시간을 낭비할 필요가 없어진다. Mock Server를 구성하는 방법도 다양하게 선택이 가능해보인다. 기존 Apollo Server에 구현되지 않은 Resolver에 대해서만 Mock을 사용 다른 Remote GraphQL Server의 schema를 받아와서 별도의 Mock Server를 구현 Server 없이 Apollo Client에서 Mock Schema Link 이용 더 자세한 사항은 공식문서를 참고하도록 하자. 마치며위와 같이 Mock Server를 구성한다면 API 때문에 Frontend 코드가 변경되는 것을 최소화 할 수 있다.server에서도 얼마 안되는 코드로 mock data를 생성하고 관리하기 때문에 부하가 큰 작업은 아니다.client에 fake data를 구성하는 방법으로도 충분할 수 있지만 GraphQL을 사용한다면 시도해볼만한 것 같다. REST API를 사용중이라면 json-server와 같은 도구가 비슷한 역할을 할 수 있다. Ref https://www.apollographql.com/docs/graphql-tools/mocking/","categories":[{"name":"graphql","slug":"graphql","permalink":"https://y0c.github.io/categories/graphql/"}],"tags":[{"name":"graphql","slug":"graphql","permalink":"https://y0c.github.io/tags/graphql/"},{"name":"apollo","slug":"apollo","permalink":"https://y0c.github.io/tags/apollo/"}]},{"title":"Golang과 Lambda를 활용한 알림 서비스 개발기","slug":"go-lambda-develop-notify-service","date":"2019-08-25T11:43:06.000Z","updated":"2019-08-25T15:24:06.422Z","comments":true,"path":"2019/08/25/go-lambda-develop-notify-service/","link":"","permalink":"https://y0c.github.io/2019/08/25/go-lambda-develop-notify-service/","excerpt":"","text":"평소에 Festa 라는 이벤트 플랫폼을 가끔씩 이용하는 편이다. 이 서비스에는 내가 관심있는 IT 관련 세미나 혹은 해커톤과 같은 밋업이 종종 올라오곤 한다. 보통은 페이스북 그룹에 공유된 글을 통해서 혹은 지인들을 통해서 알게됬는데 그럼에도 놓치는 것들이 있었다. 이번에 하던일이 끝나고 시간이 좀 남아서 Festa에 최신 이벤트에 대해서 메일로 알림을 해주는 서비스를 개발해보았다. 이 글에선 Golang과 AWS Lambda를 활용해서 알림 서비스를 개발한 것 에대해서 정리해보려고 한다. 구상처음에 했던 작업은 알림에 대한 아이디어 구상이였다. Festa에서는 이벤트에 대한 카테고리나 태그에 대해서 제공하지 않았다. 새로은 이벤트에 대해서 모두 알림을 받는 방법도 생각해봤지만 생각보다 개발과 관련없는 이벤트도 많이 올라왔다. 고민중에 주변에서 피드백을 받아 키워드를 통해서 필터링하는 방법을 선택했다. 아래 그림을 보면 이벤트에는 제목과 주최한 Host에 대한 정보가 있다. 특정 키워드를 등록해놓고 해당 키워드에 매칭된다면 메일로 알림을 해주는 방식이다. 키워드 Exmaple : GDG, 해커톤 (Festa 사이트 events 페이지 참고) 키워드를 사용하는 방법도 완벽한것 같지는 않다. 다만 지금은 이것말고 딱히 다른방법이 떠오르지 않아서 일단 구현하기로 했다. GDG에서 여는 이벤트가 많이 올라와서 이것만 등록해놔도 크게 문제는 없을것 같았다. 기술 선정GolangGolang을 공부하고 있어서 프로젝트 목적의 반은 Golang에 좀 익숙해지는데에 있었다. 다른 익숙한 언어를 사용했다면 좀 더 수월하게 개발할 수 있었지만 진행하면서 Golang에 대한 학습도 되고 괜찮았던 것 같다. Google Cloud Firestore구독자 메일과, 키워드를 저장해놓을 데이터베이스가 필요했다. 선정 기준은 무료여야했고 얼마 되지않고 단순한 데이터를 저장하는 용도라 RDB보단 NoSQL을 선호했다. Firebase가 생각나서 정말 오랜만에 들어갔는데 Realtime Database를 말고 Firestore라는 서비스를 제공하고 있었다. Realtime Database보다는 Firestore가 목적에 좀 더 적합해서 이걸 사용하게 되었다. 두 서비스의 차이점 비교https://firebase.google.com/docs/firestore/rtdb-vs-firestore?hl=ko AWS LambdaSchedule 기능이 필요해서 CircleCI Schedule 기능을 알아보다가 람다도 CloudWatch를 이용해서 Schedule 기능을 구현할 수 있다는 걸 알게되었다. Function 별로 Schedule을 설정할 수 있어서 다른 Schedule을 추가하기에도 용이했고 가격도 무료에 가까웠다. 사용해본적도 있어서 람다를 이용하게 되었다. AWS SES메일을 보내는 기능은 알림을 위해서 필수적이였다. 메일 전송에 대한 부분은 선택지가 꽤 많은 편이다. mailgun, SendGrid 등 무료와 유료 플랜 모두 지원하는 서비스가 여러개 있고 개인 Gmail을 활용하는 방법도 있었다. 처음엔 귀찮아서 내 Gmail 계정을 활용해서 테스트 하다가 AWS SES를 이용하게 됬다. 도메인만 가지고 있으면 손쉽게 Outbound메일 서버를 구축할 수 있고 비용도 사용량이 적은경우 거이 나가지 않는 듯 했다. 자세히 읽어보지는 않아서 다음달 청구서를 봐야할 것 같다. CircleCICircleCI는 단순히 Serverless Deploy 용도를 위해서 사용하고 있다. Local에서 Deploy해도 충분하지만 최종 커밋이 항상 깨지지 않는 상태를 유지하고 싶었다. Travis만 사용해봐서 CircleCI는 어떤가 사용해보려는 목적도 있었다. 구현전체적인 Flow에 대해서 먼저 생각해보면 아래와 같다. Festa에서 최신 Event 정보를 받아온다. Firestore에서 구독자 목록을 받아온다. 구독자마다 Event목록 중 알림대상이 있는지 확인한다. 알림대상이 있다면 메일을 전송한다. 위 Flow를 하나의 람다로 구성하고 일정시간마다 호출해주면 된다. Festa Event먼저 Festa 최신 Event를 받아오는 부분이다. REST API가 있었고 로그인을 하지 않아도 최신 Event를 확인할 수 있었다. 이 부분을 Go로 구현해보자. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package festaimport ( \"encoding/json\" \"fmt\" \"io/ioutil\" \"net/http\" \"strings\")// Festa struct is invoke Festa APItype Festa struct&#123;&#125;// EventResponse Festa API responsetype EventResponse struct &#123; Page string `json:\"page\"` PageSize string `json:\"pageSize\"` Total int `json:\"total\"` Rows []Event `json:\"rows\"`&#125;// New returning Festa API instancefunc New() *Festa &#123; return &amp;Festa&#123;&#125;&#125;const apiEndpoint = ... func toQueryString(params map[string]string) string &#123; arr := []string&#123;&#125; for k, v := range params &#123; arr = append(arr, fmt.Sprintf(\"%s=%s\", k, v)) &#125; return strings.Join(arr, \"&amp;\")&#125;// GetEvents return recent festa eventsfunc (f *Festa) GetEvents() (events []Event) &#123; var eventResponse EventResponse queryParam := map[string]string&#123; ... &#125; resp, _ := http.Get(fmt.Sprintf(\"%s?%s\", apiEndpoint, toQueryString(queryParam))) responseBytes, _ := ioutil.ReadAll(resp.Body) json.Unmarshal(responseBytes, &amp;eventResponse) return eventResponse.Rows&#125; Go는 JSON String을 Unmarshaling할때 Struct 형태로 변환이 가능하다. JSON 필드를 일일이 Struct로 만드는 작업은 매우 손이 많이가고 번거롭기 때문에 다른 툴을 이용해서 변환했다. JSON Response를 input으로 넣으면 Go Struct로 변환해주는 툴이다.https://mholt.github.io/json-to-go/ FirestoreFirebase 콘솔 에서 프로젝트를 생성하면 바로 Firestore 혹은 Realtime Database를 사용할 수 있다. SDK를 통해서 Firestore에 접근하려면 비공개 키가 필요하다. Firebase 프로젝트 설정에서 비공개 키를 만들고 JSON 형식의 파일로 다운받을 수 있다. Lambda에선 파일을 사용하기 어렵기때문에 파일내용을 JSON으로 환경변수에 넣어놓고 시작시에 Unmarshal 해서 사용하였다. 123456789101112131415161718192021222324252627282930313233343536373839404142// Package db provides firestore clientpackage dbimport ( \"cloud.google.com/go/firestore\" firebase \"firebase.google.com/go\" \"fmt\" \"golang.org/x/net/context\" \"google.golang.org/api/option\" \"os\")var client *firestore.Clientfunc getOption() option.ClientOption &#123; rawString := os.Getenv(\"SERVICE_ACCOUNT_KEY\") return option.WithCredentialsJSON([]byte(rawString))&#125;// GetClient return signletone firestore instancefunc GetClient() (*firestore.Client, error) &#123; if client == nil &#123; ctx := context.Background() conf := &amp;firebase.Config&#123;ProjectID: \"festa-notify\"&#125; app, err := firebase.NewApp(ctx, conf, getOption()) if err != nil &#123; return nil, fmt.Errorf(\"error initializing firebase app: %v\", err) &#125; store, err := app.Firestore(ctx) if err != nil &#123; return nil, fmt.Errorf(\"error initializing firestore: %v\", err) &#125; client = store &#125; return client, nil&#125; Firestore에 대한 instance를 Signletone 형태로 구성해놓고 도메인 별로 Service를 만드는 방식을 사용했다.Collection에 대한 Query, Update 부분은 https://cloud.google.com/firestore/docs/ 이곳에 자세하게 나와있다. AWS SES메일링을 위해서 SES를 셋업해야 한다. 생각보다 SES를 사용하는 방법은 간단하다.SES 페이지에 접속 후 Verify a New Domain 버튼을 눌러서 도메인을 검증하면 Sandbox 모드에서 사용할 수 있게된다. 실제 사용을 위해서는 Sandbox 모드 해제를 신청해야 한다. Sandbox 모드에서는 미리 인증해놓은 이메일에 한해서만 메일 전송이 가능하다. 도메인은 Freemon 에서 무료 도메인을 만들어서 사용했다. 실제로 메일을 전송할 때는 등록해놓은 도메인으로 전송이 가능하다. 지금은 메일 발송시 noreply@festa-notify.cf 이런식으로 사용하고 있다. Go 에서 SES 메일 발송을 위해선 이 예제만 참고하면 무리없이 구현할 수 있다. Serverless &amp; GoLambda 배포를 위해 Serverless 프레임워크를 사용하였다. Go를 Serverless를 통해서 Lambda에 배포하는건 Node.js에 비해 간단한 느낌을 받았다. 단순히 Go func를 만들고 Labmda 라이브러리에 해당 핸들러를 넘겨주면 된다. Serverless Blog에서 간단한 Example에 대해서 소개한다.https://serverless.com/blog/framework-example-golang-lambda-support/ 위 예제에서는 go dep를 이용하는 방법에 대해 나오는데 나는 Go modules를 사용하고 있어서 의존성 관리 부분을 제외하고는 예제를 따라서 구현했다. 이미 개발중인 프로젝트에 적용시에는 Makefile, serverless.yml 설정만 옮겨서 프로젝트에 맞게 설정해주면 쉽게 AWS Lambda로 배포할 수 있다. CloudWatch EventCloudWatch는 보통 AWS 관련로그를 보는 용도로 사용하는데 여기에 이벤트라는 기능이 있다. 이 이벤트를 이용하면 특정시간 혹은 주기적으로 어떤 람다를 호출해줄 수 있다. CloudWatch에 Event 탭으로 이동해서 규칙을 생성해주기만 하면 된다. rate 혹은 crontab 표현식으로 등록할 수 있다. 메일 알림 Github이 프로젝트의 코드는 아래 Repo에 모두 공개되어 있다.https://github.com/y0c/festa-notify 마치며 Go가 아직 익숙하지 않아서 생각보다 오래걸렸지만 언어 자체는 간편하고 장점이 많아 보인다. SES를 사용한 다른 글을 보면 Sandbox 모드 해제는 하루정도면 되는 것 같은데 주말때문인지 오래걸리는 케이스도 있는 것 같다. 작은 프로젝트지만 자세히 적으려니 생각보다 내용이 많아서 전체적인 맥락에 대해서만 간단히 정리해보았다.","categories":[{"name":"Go","slug":"Go","permalink":"https://y0c.github.io/categories/Go/"}],"tags":[{"name":"Go","slug":"Go","permalink":"https://y0c.github.io/tags/Go/"},{"name":"Lambda","slug":"Lambda","permalink":"https://y0c.github.io/tags/Lambda/"},{"name":"SES","slug":"SES","permalink":"https://y0c.github.io/tags/SES/"},{"name":"Serverless","slug":"Serverless","permalink":"https://y0c.github.io/tags/Serverless/"}]},{"title":"TDD로 Golang 시작하기","slug":"beginning-go","date":"2019-08-11T04:26:49.000Z","updated":"2019-08-11T07:27:03.866Z","comments":true,"path":"2019/08/11/beginning-go/","link":"","permalink":"https://y0c.github.io/2019/08/11/beginning-go/","excerpt":"","text":"새로운 언어를 공부할땐 책을 보면서 syntax를 익히거나 간단한 프로젝트를 진행했었다.이번엔 Go를 공부하게됬는데 TDD를 통해서 언어에 익숙해지는 방법을 시도해봤다. 이런 방법은 언어에 익숙해지면서 Test, Refactoring에도 자연스럽게 익숙해질 수 있는 장점이 있다. 이 글에선 TDD를 통해 간단하게 Go를 시작할 수 있는 방법에 대해서 정리해보려 한다. Go 개발환경 셋팅하기Go를 설치하는 방법은 두 가지가 있다. Go Download 에서 다운 받아서 설치 GVM을 이용해서 설치 나는 버전을 유연하게 관리할 수 있는 GVM 방식을 선호한다.GVM을 통한 자세한 설치방법은 아래 링크를 참고하도록 하자.https://select995.netlify.com/go/module/gvm Go 프로젝트 생성이전에 Go를 잠깐 배웠을땐 GOPATH를 워크스페이스 처럼 사용해야 해서 불편하게 개발을 했던 기억이 있다. Go Modules를 사용하면 GOPATH 바깥에서도 Go 프로젝트를 만들고 개발할 수 있다. go mod 명령을 통해 프로젝트를 생성한다. 1go mod init &lt;Repo/프로젝트 명&gt; Hello, World TDD아래 Repo에서는 Test를 작성하면서 Go에 대해서 알아갈 수 있도록 여러가지 토픽에 튜토리얼을 제공한다. https://github.com/quii/learn-go-with-tests 가장 첫 번째 토픽인 Hello, World를 시작해보자.단순히 Hello, World를 찍는 프로그램을 TDD way로 진행해 볼 수 있다. 먼저 위에서 생성한 프로젝트에 hello.go 를 만들어보자. 1234567891011package mainimport \"fmt\"func Hello() string &#123; return \"Hello, world\"&#125;func main() &#123; fmt.Println(Hello())&#125; go 에서 entrypoint는 main package 의 main 함수이다.이렇게 작성하고 go run 을 하면 Hello, world 문구가 출력된다. Hello라는 함수를 분리한 이유는 Test를 돌리기위해서이다.fmt.Println은 stdout에 출력하는 side-effect를 가지고 있기 떄문에 Test하기 어려운 함수가된다. 이제 Test code를 작성해보자.내가 해본 다른언어들은 Test를 돌리기위해서 다른 라이브러리나 프레임워크를 필요로 했다.(Java - Junit, Javascript - Jest, Mocha) Go에서는 Test를 위해서 Test Runner를 추가할 필요가 없다.단지 파일명을 xxx_test.go 형식으로 만들어주면 된다. 이 예제에서는 hello.go로 작성했기때문에 hello_test.go 로 만들어주면 된다. hello_test.go123456789101112package mainimport \"testing\"func TestHello(t *testing.T) &#123; got := Hello() want := \"Hello, world\" if got != want &#123; t.Errorf(\"got %q want %q\", got, want) &#125;&#125; 여기서 got은 Test할 함수가 반환한 결과값이고 want는 Test에서 기대하는 값(expect)라고 볼 수 있다.내장 모듈인 testing에는 Test를 위한 여러 유틸리티 함수들이 있다.(Error, Log, Run…)위 Test Code는 기대값과 실제 결과가 다르면 error를 내는 코드이다.Assertion을 사용하려면 다른 라이브러리를 추가해야한다. go test 명령을 통해서 작성해본 test가 정상적으로 동작하는지 알 수 있다. 일반적으로 개발할때는 실제 코드를 먼저 작성하고 정상적으로 동작하는지 실행을 해보거나 디버그로 버그를 찾는 식이다. TDD로 개발을 한다면 실제 코드보다 먼저 테스트를 작성하도록 권장한다. 전체적인 프로세스를 정리해보면 이런식일 것이다. 실패하는 Test 작성 Test를 Pass할 수 있는 최소한의 코드를 작성 리팩토링 (RED -&gt; GREEN -&gt; REFACTOR)만약 TDD 프로세스를 잘 모르겠다면 이 부분에 대해서 먼저 공부해는 것도 좋을 것 같다. 요구사항이 추가되었다. 단순히 Hello, world를 찍지 않고 인자로 이름을 받아서 처리하도록 변경해보자. 위 TDD 프로세스대로 먼저 테스트를 변경한다. 123456got := Hello(\"Chris\")want := \"Hello, Chirs\"if got != want &#123; t.Errorf(\"got %q want %q\", got, want)&#125; 이와 같이 먼저 어떤식으로 Hello라는 함수를 사용하고 어떤 결과를 기대하는지 작성한다.IDE를 사용한다면 바로 lint error가 뜨는 것을 볼 수 있을것이다. (RED) 실제코드를 간단히 변경해서 Test를 Pass하도록 변경할 수 있다. (GREEN)123func Hello(name string) string &#123; return \"Hello, \" + name&#125; Test를 돌려보자. OK 문구가 뜨는걸 볼수 있을것이다.(만약 FAIL이 난다면 타이핑 실수를 하지 않았는지 확인해보자) 이제 리팩토링할 단계이다. 사실 이 코드에서는 리팩토링할 부분이 많지않다.단순히 “Hello, “ 부분을 상수로 분리한다. 1234const englishHelloPrefix = \"Hello, \"func Hello(name string) string &#123; return englishHelloPrefix + name&#125; 다시 Test를 돌려보자. (go test)Success가 나오는 걸 확인할 수 있다. 만약 어떤 실수를 했다면 FAIL과 함께 Test code가 피드백을 줄 것이다. 다음 요구사항은 name 인자에 empty가 넘어올경우 기본값을 world로 설정해주는것이다.테스트 해야될 사항이 두가지로 늘어났다. empty string(“”) 이 넘어올경우 Hello, world를 출력하는지 그리고 empty가 아닌 string이 넘어올 경우 하나의 Test case에서는 한 가지에 대해서만 명확히 Test를 작성하는 것이 좋다.두가지 Test case로 분리해보자. 123456789101112131415161718192021func TestHello(t *testing.T) &#123; t.Run(\"saying hello to people\", func(t *testing.T) &#123; got := Hello(\"Chris\") want := \"Hello, Chris\" if got != want &#123; t.Errorf(\"got %q want %q\", got, want) &#125; &#125;) t.Run(\"say 'Hello, World' when an empty string is supplied\", func(t *testing.T) &#123; got := Hello(\"\") want := \"Hello, World\" if got != want &#123; t.Errorf(\"got %q want %q\", got, want) &#125; &#125;)&#125; TestHello 라는 함수는 Test Suite로 t.Run은 하나의 Test Case로 볼 수 있을 것 같다.아직 empty string에 대해 처리하지 않았기 때문에 에러가 날 것이다. 위에서 진행헀던 프로세스그대로 Test를 Pass할 수 있는 코드를 작성하고 리팩토링을 하면 된다. Test를 Pass 시키기 전에 Test Code를 리팩토링 해보자. 지금은 got, want의 값이 다를 경우 error를 내는 부분이 중복되어있고 정확히 어떤 역할을 하는지 한 눈에 파악하기 어렵다. 1234567891011121314151617181920assertCorrectMessage := func(t *testing.T, got, want string) &#123; t.Helper() if got != want &#123; t.Errorf(\"got %q want %q\", got, want) &#125;&#125;t.Run(\"saying hello to people\", func(t *testing.T) &#123; got := Hello(\"Chris\") want := \"Hello, Chris\" assertCorrectMessage(t, got, want)&#125;)t.Run(\"say 'Hello, World' when an empty string is supplied\", func(t *testing.T) &#123; got := Hello(\"\") want := \"Hello, World\" assertCorrectMessage(t, got, want)&#125;) assertCorrectMessage 라는 함수로 assert부분을 분리한다. 중복이 없어지고 가독성도 훨씬 좋아질 것이다. t.Helper() 함수는 error가 난 라인을 추적할 수 있도록 도와준다. 사용하지 않아도 라인을 알려주지만 정확히 에러가 난 라인이 아닌 assertCorrectMessage 함수가 있는 라인넘버를 알려줄 것이다. Test를 Pass하도록 코드를 작성한다.1234567const englishHelloPrefix = \"Hello, \"func Hello(name string) string &#123; if name == \"\" &#123; name = \"world\" &#125; return englishHelloPrefix + name&#125; 다음 단계는 리팩토링이지만 여기선 그럴부분이 딱히 없어서 그대로 두면 될 것 같다. 위에서 소개한 Repo의 원문글을 보면 뒤에 2가지 단계 정도를 더 진행한다.끝까지 진행해보면 TDD cycle을 익히는데 도움이 될 것 같다. Tip go test -v go test는 실패하면 실패한 Test Case를 알려주지만 성공시에는 성공했다는 OK 문구 하나만 나온다. test case를 같이 출력하고 싶다면 -v 옵션을 추가해보자 testify/assert 위 라이브러리를 사용하면 assert관련 여러 함수를 사용할 수 있다. 이런 함수들은 Test 실패시 실제 결과값과 어떤식으로 다른지 diff checking과 같은 부분도 제공을 하기 때문에 편리하다. 마치며위 Hello, World는 정말 간단한 예제이지만 TDD 개발의 cycle에 익숙해질 수 있고 복잡하지 않은 코드를 연습하면서 언어를 익히는데도 도움이 많이 되었던 것 같다. go 를 새로 공부해야 한다면 TDD를 통해서 배우는 것도 괜찮은 방법일 것 같다. Ref https://github.com/quii/learn-go-with-tests https://select995.netlify.com/go/module/gvm","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"https://y0c.github.io/tags/Go/"},{"name":"TDD","slug":"TDD","permalink":"https://y0c.github.io/tags/TDD/"}]},{"title":"Vim Configuration 정리","slug":"vim-config-for-js-developer","date":"2019-07-14T11:31:10.000Z","updated":"2019-07-14T13:41:45.085Z","comments":true,"path":"2019/07/14/vim-config-for-js-developer/","link":"","permalink":"https://y0c.github.io/2019/07/14/vim-config-for-js-developer/","excerpt":"","text":"개발을 할때 에디터로 주로 Vim을 사용한다. 상황에 따라 Visual Studio Code 혹은 WebStorm과 같은 IDE에 Vim Plugin을 올려서 사용하거나 터미널 기반으로만 사용하기도 했다. 최근엔 WebStorm과 같이 사용하다가 무겁다는 느낌을 많이 받아서 터미널 기반으로 다시 설정하고 설정한 내용들을 정리해보려고 한다. Neovim언제부턴가 기본 vim보다는 neovim을 설치해서 사용하고 있다. neovim을 설치해서 쓰는 이유는 vim보다 많은 color를 지원하고 성능면에서도 많이 발전했다고 한다. 설정이나 사용면에 있어서 vim에서 크게 벗어나지 않아 vim을 사용했다면 neovim으로 넘어가는데 문제는 없을 것 같다. 먼저 Neovim과 theme, icon에서 사용될 font를 설치해준다.123brew install neovimbrew tap caskroom/fontsbrew cask install font-hack-nerd-font 설치가 완료되었다면 vi, vim 대신 neovim을 실행하도록 설정을 추가한다.(사용하는 shell 에따라, ~/.zshrc, ~/.bashrc)1234alias vim=\"nvim\"alias vi=\"nvim\"alias vimdiff=\"nvim -d\"export EDITOR=/usr/local/bin/nvim 추가했다면 source 명령을 통해 적용해준다. 이제 ~/.config/nvim/init.vim 에서 neovim에 대한 설정을 할 수 있다. Vim Plugin 설정Vim은 플러그인 매니저로 Vim Plug, Bundle과 같은 도구를 이용한다.요즘은 Bundle보다는 Plug를 많이 사용하는 것 같아 Plug를 선택했다. Vim Plug 설치는 Plug Github을 참고해서 설치하도록 한다. Plugin 설치 방법neovim 설정 파일을 연다. (~/.config/nvim/init.vim)123456call plug#begin()&quot;&quot; Plugin ListPlug &apos;junegunn/fzf&apos;call plug#end() 위와 같이 plugin 설정에 대한 시작과 끝을 표시하고 중간에 설치할 Plugin List를 작성하는 형식이다.필요한 플러그인에 대해 검색해보고 github repository를 찾아서 owner와 repository name을 아래와 같은 형식으로 적어주면 된다.Plug &#39;&lt;owner&gt;/&lt;repository_name&gt;&#39; 이렇게 설정파일을 만들고나서 vi command 모드에서 :PlugInstall 을 해주면 차례대로 Plugin이 설치되는 것을 볼 수 있다. clean, upgrade와 같은 추가적인 명령에 대해서는 Plug Github을 참고도하도록 하자. 유용한 Vim Plugin들개발언어나 개발환경에 따라 사용하는 플러그인이 많이 다르겠지만 공통적으로 유용하게 사용하는 Plugin에 대해 소개해보려고 한다. NERD Treevim 에서 파일 탐색기를 지원해주는 플러그인이다. IDE까지는 아니더라도 비슷하게 흉내내서 사용할 수 있다.또한 이 Plugin은 vim 에서 사용하는 키를 그대로 사용해서 컨트롤 할 수 있어서 정말 편리하다.마우스를 사용하지 않고 파일을 컨트롤 할 수 있는게 큰 장점이다. 설치하는 방법은 플러그인 마다 다르지 않기 떄문에 위 설치 방법을 참고하면 된다.scrooloose/nerdtree 추가적인 설정123456&quot;&quot; Dir Arrow 설정let g:NERDTreeDirArrowExpandable = &apos;▸&apos;let g:NERDTreeDirArrowCollapsible = &apos;▾&apos;&quot;&quot; 숨김파일 보이도록 처리let NERDTreeShowHidden=1 숨김파일에 대한 설정을 해주지 않으면 .gitignore, .env와 같은 파일들이 보이지 않아 불편하다. NERDtree Git PluginNERDTree 상에서 Git에 대한 변경내용을 표시해준다.이것도 바뀐파일을 확인할때 유용하므로 꼭 설치해두자.Xuyuanp/nerdtree-git-plugin_ Vim dev-icons여러 vim 플러그인에서 개발관련 icon을 사용할 수 있게 해주는 plugin이다.NERDTree에서도 Icon을 표시해줘서 파일확장자를 보지 않아도 쉽게 구분할 수 있다.아이콘이 깨지지 않고 표시되려면 위에 있는 폰트를 반드시 설치해줘야 한다.ryanoasis/vim-devicons Vim airlinevim 상태바를 이쁘게 만들어준다.상태바에는 vim 모드, git branch, 파일 인코딩 과 같은 정보가 들어가게 된다.다른 플러그인과 연동도 잘되고 가장 많이 쓰이는 플러그인 중 하나이다.vim-airline/vim-airline Vim fugitivevim에서 git을 사용할때 유용한 plugin이다.git cli 에서 제공하는 기능을 대부분 사용할 수 있으며 cli를 사용하는 것 보다 매우 편리하다.vimcast에서 자세한 사용방법에 대해 설명해준다.tpope/vim-fugitive ctrlp대부분에 IDE에서는 특정 단축키를 통해서 특정파일을 검색하고 이동하는 기능을 제공한다.ctrlp 플러그인은 vim 에서 이와 같은 작업을 할 수 있도록 도와준다.플러그인 이름과 같이 ctrl+p를 누르면 파일을 검색하고 이동할 수 있다.ctrlpvim/ctrlp.vim aleale는 vim에서 lint, syntax check를 위한 플러그인이다.다른 플러그인도 여러개있지만 성능면에서 ale가 우수하다고 한다.eslint, prettier와 같은 툴과도 같이 사용할 수 있다. 실제 개발을 위해선 위에서 소개한 플러그인 말고도 여러가지를 더 설치해야 한다. 현재 Vim Configuration아래 내용은 내가 셋탱해놓은 Vim configuration 이다.한번 지우고 필요한 것만 다시 설치하느라 빠뜨린게 많을 수 있다. 개발화면 위 화면에서는 vim과 tmux를 함께 사용하는 화면이다.tmux 에 관련해서는 tmux 포스팅을 참고하도록 하자. 마치며IDE에 Vim Plugin을 올려서 사용하는 것과 terminal 상에서 vim을 customize해서 사용하는 것 모두 장단점이 존재한다. vim 설정을 공부하고 일일이 plugin을 설치하는 것은 매우 귀찮고 시간도 많이 들어가는 작업임이 분명하다. 하지만 한 번 설정해놓으면 IDE보다 가볍게 사용할 수 있고 거이 모든 작업을 키보드로 할 수 있다. IDE가 무겁거나 한 번쯤 새로운 환경을 만들어 보고 싶다면 시도해볼만 한 것 같다. Ref https://subicura.com/2017/11/22/mac-os-development-environment-setup.html https://github.com/akrawchyk/awesome-vim","categories":[{"name":"vim","slug":"vim","permalink":"https://y0c.github.io/categories/vim/"}],"tags":[{"name":"vim","slug":"vim","permalink":"https://y0c.github.io/tags/vim/"},{"name":"tool","slug":"tool","permalink":"https://y0c.github.io/tags/tool/"}]},{"title":"React Infinite scroll 구현하기","slug":"react-infinite-scroll","date":"2019-06-30T07:00:05.000Z","updated":"2019-06-30T10:33:11.241Z","comments":true,"path":"2019/06/30/react-infinite-scroll/","link":"","permalink":"https://y0c.github.io/2019/06/30/react-infinite-scroll/","excerpt":"","text":"React로 Infinite scroll을 구현하면서 정리한 글이다. Infinite scroll?Infinite scroll은 한 번에 모든 컨텐츠를 렌더링 하지 않고 페이지 내용을 아래로 스크롤하면 새로운 컨텐츠를 덧붙여서 렌더링 하는 방식이다. 로딩해야할 컨텐츠의 양이 많다면 퍼포먼스 측면에서 infinite scroll을 고려해 볼 수 있다. 페이스북 혹은 트위터와 같은 사이트를 보면 이와 같은 UI를 적극적으로 사용하고 있다. 구현 방법Infinite Scroll을 구현하는 방법에는 크게 두 가지가 있다. onScroll event Intersection Observer API onScroll eventonScroll event를 이용한 방법은 가장 먼저 생각해 볼 수 있는 방법이다. 사용자가 scroll을 할 때 이벤트가 발생하고 현재 scroll 위치가 페이지에 끝에 닿았는지 판단한다. 페이지 끝에 도달했다면 새로운 컨텐츠를 로딩하기 위한 요청을 하고 컨텐츠를 덧붙이는 방식이다. 하지만 scroll 이벤트는 굉장히 빈번하게 발생하기 때문에 성능 최적화를 위해서 throttle과 같은 처리가 필요하다. Intersection Observer APIIntersection Observer는 MDN 에서 아래와 같이 설명한다. 교차 영역 관찰자 API는 조상 엘리먼트 또는 최상위 도큐먼트 뷰포트와 대상 엘리먼트의 교차 영역에서 발생한 변경 사항을 비동기적으로 감시하는 방법을 제공한다. 위 정의만 읽어보면 말이 어려울 수 있는데 단순하게 DOM 엘리먼트 간에 영역이 겹쳐지는걸 감시한다고 볼 수 있다. Intersection Observer API를 사용하면 scroll, resize와 같은 비싼 비용의 이벤트를 좀 더 쉽고 좋은 퍼포먼스로 사용할 수 있다. Lazy-load, infinite scroll 과 같은 것들을 구현할때 유용하게 사용할 수 있다. scroll 이벤트에 비해 단점이라면 아직 모든 브라우저에서 지원하지 않는다는 것이다. 이 글에선 IntersectionObserver 에 대한 자세한 설명은 하지 않는다. 더 필요한 정보는 아래 링크를 참고하도록 하자. https://velog.io/@doondoony/IntersectionObserver 사실 브라우저 지원과 특수한 상황을 제외하곤 Intersection Observer API가 구현하기 편리하기 때문에 이 방법을 통해서 Infinite scroll을 구현하였다. React를 통한 구현구현하려고 했던 것은 Unsplash API를 통해서 이미지를 검색하고 결과를 Infinite scroll 을 통해 보여주는 것이였다. Component 구조가장 먼저 했던 작업은 Component 구조를 잡는 것 이였다.123456789101112131415161718192021const UnsplashContainer = () =&gt; &#123; //... return ( &lt;div&gt; &lt;SearchForm onSearch=&#123;searchImage&#125; /&gt; &lt;ScrollContainer height=&#123;400&#125; vertical ref=&#123;rootRef&#125; &gt; &lt;ThumbnailList thumbnails=&#123;images&#125; /&gt; &lt;Loading show=&#123;loading&#125;/&gt; &lt;div ref=&#123;targetRef&#125; /&gt; &lt;/ScrollContainer&gt; &lt;/div&gt; )&#125;; 컴포넌트 구조는 scroll 가능한 div를 셋팅해두고 그 아래에 컨텐츠 목록, 로딩 컴포넌트 그리고 마지막으로 IntersectionObserver 를 활용해서 페이지 끝을 감지하기 위해 빈 div를 추가하였다. React State이제 Component에서 필요한 변수, 상태, ref를 추가해야 한다.1234567891011121314// instance variableconst currentPage = useRef(1);const totalPage = useRef(0);// request stateconst [loading, setLoading] = useState(false);const [error, setError] = useState(null);// contents listconst [images, setImages] = useState([]);// refconst rootRef = useRef(null);const targetRef = useRef(null); currentPage와 totalPage는 state로 관리할 필요는 없었기 때문에 Ref로 추가하였다.(React Hooks에서 useRef는 이전값을 저장하거나 class component의 멤버 변수와 같이 사용할 수 있다.)rootRef와 targetRef는 IntersectionObserver에서 사용할 실제 DOM 노드들이다. Data FetchingData Fetching을 위한 함수를 몇가지 정의한다. 12345678910111213141516171819202122232425262728293031323334const loadImage = useCallback(async (&#123; query, page &#125;) =&gt; &#123; try &#123; setLoading(true); const data = await UnsplashAPI.searchPhotos(&#123; query, page, per_page: PER_PAGE&#125;); totalPage.current = data.total_pages; return data; &#125; catch(e) &#123; setError(e); &#125; finally &#123; setLoading(false); &#125;&#125;, []);const searchImage = useCallback(async (query) =&gt; &#123; if(!query) &#123; await loadRandomImage(); return; &#125; currentQuery.current = query; currentPage.current = 1; const data = await loadImage(&#123; query, page: 1, per_page: PER_PAGE &#125;); setImages(data.results);&#125;, [loadImage, loadRandomImage]);const loadMoreImage = useCallback(async () =&gt; &#123; if(images.length &gt; 0) &#123; currentPage.current++; const data = await loadImage(&#123; query: currentQuery.current, page: currentPage.current &#125;); setImages([...images, ...data.results]) &#125;&#125;,[images, loadImage]); loadImage는 Unsplash API를 통해서 Data를 가져오고 loading과 error 상태를 제어한다. searchImage는 맨 처음 데이터 요청에만 사용한다. 폼에서 검색을 실행하면 이 함수가 호출된다. loadMoreImage 함수는 스크롤이 끝에 닿았을때 호출된다. 여기선 페이지값을 증가시키고 컨텐츠 뒤쪽으로 새로운 컨텐츠를 붙여주면 된다. (useAsyncFn hook을 사용하면 loading, error를 좀 더 깔끔하게 관리할 수 있다. react-use 패키지에서 사용하거나 혹은 구현해도 무관하다.) IntersectionObserver hookIntersectionObserver를 설정해준다. 이 부분은 검색해보면 라이브러리도 많고 일반적인 예제들도 많이 있다. 상황에 맞춰서 사용하면 될 것 같다. 나는 다른 코드를 참고해서 custom hook을 추가했다. useIntersectionObserver.jsx 12345678910111213141516171819202122232425262728import &#123; useEffect &#125; from \"react\";export default (&#123; root, target, onIntersect, threshold = 1.0, rootMargin = \"0px\" &#125;) =&gt; &#123; useEffect( () =&gt; &#123; if (!root) &#123; return; &#125; const observer = new IntersectionObserver(onIntersect, &#123; root, rootMargin, threshold, &#125;); if (!target) &#123; return; &#125; observer.observe(target); return () =&gt; &#123; observer.unobserve(target); &#125;; &#125;, [target, root, rootMargin, onIntersect, threshold] );&#125;; root, threshold, rootMargin은 IntersectionObserver의 옵션들이고 target은 교차에 대해서 감시할 element 이다. onIntersect는 IntersectionObserver의 callback이라고 생각하면 된다. 위 컴포넌트 구조에서 root는 ScrollContainer로 target은 맨끝에 빈 div로 설정하였다. onIntersect 에서 몇가지 조건에 맞춰서 loadMoreImage를 호출해주면 infinite scroll이 완성된다. 12345678910111213useIntersectionObserver(&#123; root: rootRef.current, target: targetRef.current, onIntersect: ([&#123;isIntersecting&#125;]) =&gt; &#123; if( isIntersecting &amp;&amp; !loading &amp;&amp; currentPage.current &lt; totalPage.current ) &#123; loadMoreImage(); &#125; &#125;&#125;); 나는 위와 같은 조건을 추가해서 구현했다. 로딩중이거나 마지막 페이지가 아닐때 페이지끝에 닿으면 추가로 로딩하는 로직이다. 구현 화면 이 프로젝트는 블로그 포스트 배너를 생성해주는 banner-maker 라는 프로젝트이다.Unsplash Image를 배경으로 활용할 수 있도록 기능을 추가해서 기여해 보았다. 마무리scroll event를 활용해서 구현하는 것 보다 IntersectionObserver를 이용하면 좀 더 손쉽게 infinite scroll을 구현할 수 있었다. IntersectionObserver의 브라우저 지원현황이 걸린다면 polyfill을 사용할 수 있지만 완벽하진 않은 것 같다. Ref https://velog.io/@doondoony/IntersectionObserver https://developer.mozilla.org/en-US/docs/Web/API/Intersection_Observer_API https://github.com/streamich/react-use","categories":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/categories/React/"}],"tags":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/tags/React/"}]},{"title":"📦 Monorepo Tutorial","slug":"monorepo-tutorial","date":"2019-06-14T10:17:37.000Z","updated":"2019-06-17T16:03:59.500Z","comments":true,"path":"2019/06/14/monorepo-tutorial/","link":"","permalink":"https://y0c.github.io/2019/06/14/monorepo-tutorial/","excerpt":"","text":"Monorepo에 대해 학습한 내용을 정리한 글이다. 📦 Monorepo?여러 프로젝트를 진행하다 보면 동일한 모듈을 다른 프로젝트에도 같이 사용해야 될 경우가 생긴다. 예를 들어 backend에서 admin 과 실제 서비스 프로젝트 간의 모델, 도메인 비지니스 로직에 대한 코드나 혹은 react와 react-native 사이의 컴포넌트 공유 등 여러가지 케이스가 있을 수 있다. 이렇게 모듈을 공유해야되는 상황에서 중복되는 모듈마다 리포지토리 분리해서 패키지 매니저에 등록하고 사용하게 되면 개발, 테스트, 배포 에 있어서 관리하기가 어려워진다. 모노리포는 하나의 리포지토리에 여러 패키지들을 두는 구조이다. Monorepo 장점 test, build, release 프로세스를 한 번에 진행할 수 있다. 하나의 저장소에서 issue를 처리할 수 있다. 모듈별로 개별적인 버전관리 패키지 매니저에 등록하지 않고도 코드를 공유하기 쉬워진다. Monorepo 단점 러닝커브 와 초기셋팅 커진 리포지토리 사이즈? 이것 말고도 모노리포로 구성해서 좀 더 번거로워 지는 부분들도 있겠지만 좀 더 사용해봐야 할 것 같다. Monorepo를 구성하는 방법모노리포는 리포지토리를 구성한는 형식이기 때문에 여러가지 도구를 통해서 구성할 수 있다. 별다른 도구 없이도 하나의 리포안에 폴더를 구분하고 node_module간의 심볼릭 링크를 통해서 구현할 수 있겠지만 매번 링크를 거는 방법은 비효율적이고 번거롭다. 여기선 가장 많이 사용하는 방법인 Yarn workspace 와 Lerna 에 대해 간단히 소개해보려고 한다. Yarn workspaceyarn workspace는 패키지 아키텍쳐를 설정하는 새로운 방법이고 기본적으로 1.0버전부터 사용할 수 있다고 한다. yarn workspace를 이용하면 좀 더 쉽게 모노리포 안에 여러 패키지들의 의존성을 관리할 수 있다. root 폴더와 패키지들로 구성할 수 있는데 모든 패키지들에 대한 의존성을 한번의 yarn install 로 처리할 수 있다. 또한 모듈은 hoist 되어서 root 폴더의 node_modules 폴더에 설치된다. 물론 공통된 모듈인데 버전만 다를 경우엔 해당 패키지 node_modules에 설치된다. 아래 튜토리얼을 따라해보면 어떤식으로 동작하는지 좀 더 쉽게 이해할 수 있다. Repo Structure구성해보려고 하는 모노리포의 구조는 다음과 같다. 보통 packages라는 폴더 아래 패키지들을 모아서 관리하지만 다른이름으로 바꿔도 무관하다. 12345├── package.json└── packages ├── server ├── shared └── web root package.json 작성 root directory는 패키지로 배포될리 없기 때문에 private으로 설정하고 workspaces에는 패키지 폴더명을 배열로 넘길 수 있다. 패턴도 사용이 가능하다. yarn init 후 아래 property를 추가해주면 된다. 123456&#123; &quot;private&quot;: true, &quot;workspaces&quot;: [ &quot;packages/*&quot; ] &#125; 패키지별 package.json 생성 123cd packages/shared &amp;&amp; yarn init -ycd packages/server &amp;&amp; yarn init -ycd packages/web &amp;&amp; yarn init -y 패키지명 변경 package.json 이 생겼지만 npm 에서 따로 설치한 모듈과 구분해주기 위해서 앞에 prefix를 붙여주는 것이 좋다. 여기선 예시로 @project로 설정하였다. 123456&#123; \"name\": \"@project/server\", \"version\": \"1.0.0\", \"main\": \"index.js\", \"license\": \"MIT\"&#125; yarn install root 폴더로 이동후 yarn install 을 하면 node_modules에 패키지들이 심볼릭 링크가 자동으로 걸려있다. 이걸통해서 패키지간에 모듈 상호참조가 가능해진다. 1234└── @project ├── server -&gt; ../../packages/server ├── shared -&gt; ../../packages/shared └── web -&gt; ../../packages/web 간단한 코드 작성 shared 패키지에 어떤함수를 추가하고 server패키지에서 shared모듈을 참조해서 사용하는 예시이다. packages/shared/index.js 123module.exports = () =&gt; &#123; console.log('Hello Shared!');&#125;; shared 모듈을 로딩하기전에 server패키지에 shared를 의존성으로 추가해주어야 한다. (수동으로 추가해도 무방하다.) 1yarn workspace @project/server add @project/shared@1.0.0 packages/server/index.js 12const sharedFunc = require('@project/shared');sharedFunc(); server/index.js 실행 1node packages/server/index npm 모듈 추가 (hoist) packages/server/package.json 123456\"dependencies\": &#123; \"@project/shared\": \"1.0.0\", \"axios\": \"^0.19.0\", \"jest\": \"^24.8.0\", \"query-string\": \"^6.7.0\"&#125; packages/web/package.json ,packages/shared/package.json 12345\"dependencies\": &#123; \"query-string\": \"^6.7.0\", \"jest\": \"24.0.0\", \"axios\": \"0.18.0\"&#125; 모듈을 다음과 같이 추가한 후 root에서 yarn install 을 하면 패키지별로 공통된 모듈에 같은 버전이라면 hoist되어서 root 폴더에 node_modules에 설치된다. 버전이 다르다면 패키지아래 node_modules가 사용될 것이다. 만약 hosit를 기능으로 인해 경로상의 문제나 다른 문제가 발생한다면 nohoist 옵션을 사용할 수 있다. 이에 대한 자세한 설명은 아래 참조 링크를 남겨두었다. LernaLerna는 모노리포의 workflow를 최적화 시켜주는 툴이다. 여기서 말하는 workflow란 test, build, versioning, publishing 등과 같은 활동들을 뜻한다. 물론 모노리포안에 여러 패키지간의 의존성을 관리해주는 일도 하고 있다. 그러나 최근에는 의존성관리 와 같은 기능은 yarn workspace에 위임하여 같이 사용하는 추세인 것 같다. 이 글에선 yarn workspace와 같이 사용하는 튜토리얼을 만들어보었다. 위에서 구성해놓은 yarn workspace에 lerna를 추가한다. lerna는 root에 설치해야하므로 -W 옵션을 붙여서 추가할 수 있다. 1yarn add -W -D lerna lerna 설정파일을 만들어준다. 1npx lerna init yarn workspace와 같이 사용하기 위해 lerna.json파일을 수정한다. 12345&#123; \"useWorkspaces\": true, \"npmClient\": \"yarn\", \"version\": \"0.0.0\"&#125; 모든 패키지에 test scripts를 추가한다. 해당 스크립트는 단순히 콘솔에 패키지명을 출력해준다. 123\"scripts\": &#123; \"test\": \"echo test $npm_package_name\"&#125; lerna run command를 통해서 패키지의 script를 실행시킨다. 1npx lerna run test 출력결과 123test @project/webtest @project/sharedtest @project/server —scope 옵션을 통해서 특정 패키지만 실행하는 것도 가능하다. 1npx lerna run test --scope=&#123;@project/web,@project/server&#125; lerna 에는 run말고도 유용한 command가 많이 존재한다. 아래에는 간단히 주요명령어에 대해 정리해보았다. lerna bootstrap - 패키지들의 의존성을 설치한다. yarn workspace를 사용중이라면 yarn에 위임한다. lerna clean - 패키지에 node_modules 폴더를 모두 삭제한다. lerna run - 패키지의 특정 scripts를 실행할 수 있다. lerna exec - 패키지 경로에서 특정 command를 실행할 수 있다. lerna version - 패키지별로 변경된 패키지만 version bump 자세한 옵션이나 사용예시는 lerna github page을 참고하도록 하자. 마무리프로젝트를 하다보면 “이 모듈은 다른곳에서도 쓰일 것 같은데?” 이렇게 생각해본게 많이 있었던 것 같다.진행했던 react프로젝트 중 여러 프로젝트에서 공통적으로 사용하는 UI들은 storybook과 함께 component 모음을 만들어두고 사용한 적이 있다. 하지만 프로젝트 리포지토리가 분리되어 있었고 같이 사용하기 위해선 npm git repository를 이용하거나 git submodule을 선택해야했는데 개발을 위해서 프로젝트를 여러개 띄워야하고 조그만 변경에도 버전을 올리고 다시 받아야되서 번거로웠던 경험이 있다. 만약 모노리포로 구성되어있다면 좀 더 나은 방법으로 관리할 수 있지 않았을까 하는 생각이 든다.모노리포가 멀티리포보다 무조건 좋다고 생각하진 않는다. 다만 프로젝트를 구성하는 방법도 여러가지 알아두면 상황에 맞춰서 좋은 구조를 선택할 수 있을것 같다. Ref https://yarnpkg.com/blog/2017/08/02/introducing-workspaces/ https://yarnpkg.com/en/docs/workspaces https://yarnpkg.com/blog/2018/02/15/nohoist/ https://github.com/lerna/lerna","categories":[{"name":"javascript","slug":"javascript","permalink":"https://y0c.github.io/categories/javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://y0c.github.io/tags/javascript/"},{"name":"yarn","slug":"yarn","permalink":"https://y0c.github.io/tags/yarn/"},{"name":"monorepo","slug":"monorepo","permalink":"https://y0c.github.io/tags/monorepo/"}]},{"title":"Testing & Refactoring","slug":"testing-refactoring","date":"2019-04-11T13:35:39.000Z","updated":"2019-04-18T16:31:22.296Z","comments":true,"path":"2019/04/11/testing-refactoring/","link":"","permalink":"https://y0c.github.io/2019/04/11/testing-refactoring/","excerpt":"","text":"필자는 개발을 시작하고 Testing에 대해서 꾸준히 들어왔다. 관련 세미나에 참석해서 내용을 들어 보기도 하고 실무 혹은 사이드 프로젝트를 통해서 적용해 보려고 여러번 시도했다. 시도 할때 마다 느꼈던 점은 어떤 식으로 테스트 코드 작성을 시작해야 될지 막막 했고 작성 하다가도 일정 상의 이유 혹은 관리의 어려움 등의 문제로 좌절 했던 기억이 있다. 더 이상 미루기만 할 수 없다고 생각해서 이번 기회에 테스팅과 리팩토링에 대해서 정리하고 연습 해보려고 한다. 개발자들은 항상 새로운 프로젝트를 시작할 때 여러가지 고민을 하게 된다. 어떤 기술을 적용할 것인지 지난 프로젝트에서 아쉬웠던 점은 어떤 것들이 있는지 좀 더 좋은 설계를 하려면 어떻게 해야 되는지 하지만 실제로 프로젝트를 시작하면 내가 생각했던 이상적인 방향으로만 흘러가지는 않는다. 요구사항은 자주 변경되고 처음에 작성한 구조는 내일의 내가 봤을때 만족하지 못한다. 이건 개발자의 기량에 상관없이 계속해서 하게되는 고민일지도 모른다. 그렇다면 여기에 대한 해결책은 없을까? 해결책은 있다. 누구나 한 번에 모든 변경사항에 대처해서 코드를 작성할 수 없다면 지속적으로 개선해 나가면 된다. 즉, 리팩토링이 필요한 시점이다. 🛠 리팩토링(Refactoring)외부 동작을 변경시키지 않으면서 내부 구조를 개선해 나가는 방법 리팩토링 이란 위 정의와 같이 동작에 영향을 주지 않으면서 내부 구조를 개선 해나가는 방법이다. 리팩토링이 어려운 이유는 &quot;두려움&quot; 에 영향이 있을 거라고 생각한다. 현재 잘 동작하고 있는 어플리케이션 의 구조를 바꾸고 정상적으로 동작할까? 버그가 생기진 않을까? 와 같은 생각이 들게 된다. 모든 개발자들이 해당되지 않을 수 있다. 필자의 경우 위와 같은 이유로 리팩토링 을 뒤로 미뤘던 경험이 있다. 지속적으로 개발한 코드를 개선하고 발전시켜 나가려면 리팩토링의 &quot;두려움&quot;을 극복할 수 있는 방법이 필요하다. 이에 대한 효율적인 방법은 &quot;자동화된 테스트&quot; 이다. 단위 테스트를 작성하고 이를 자동화 시켜 놓으면 코드를 개선해 나갈때 마다 내가 작성해 놓은 테스트 케이스 들이 어느 부분에 영향을 주고 있고 어떤 부분이 실패하고 있는지 피드백을 줄 것이다. 이런 피드백을 통해서 코드를 안정적으로 또 점진적으로 개선해 나갈 수 있다. 위 그래프는 시간에 따른 변경 비용을 그래프로 나타낸 것이다. 테스트 코드를 작성한 경우엔 시간이 지나도 변경에 대한 비용이 일정하게 유지가 되는데 테스트 코드가 없는 경우엔 시간이 지날수록 변경에 대한 비용이 지속적으로 증가하는 것을 알 수 있다. 테스트 주도 개발(Test-Driven-Development)처음 TDD라는 방법론을 듣고 접했을 땐 단위 테스트를 작성하는 것이 곧 TDD를 하는 것과 동일하다고 잘못 인지를 한 적이 있다. TDD 즉 테스트 주도 개발은 말 그대로 테스트를 먼저 작성하는 것이다. 일반적으로 개발을 할땐 바로 실제 코드를 작성하게 되지만 TDD에서는 테스트 코드를 먼저 작성하는 것을 원칙으로 한다. 전체적인 사이클을 살펴보면 위 그림과 같다. 실패하는 테스트 케이스를 작성 최대한 빠르게 테스트 케이스를 통과 리팩토링 먼저 실패하는 테스트 케이스를 작성한다. 이 테스트 케이스는 패스는 물론 컴파일도 제대로 되지 않을 것이다. 다음은 최대한 빨리 테스트 케이스를 통과시킨다. 이 과정에서는 작성이 되지 않은 클래스를 작성하고 임시로 예상 값과 동일하게 반환을 해서 통과만 시켜주면 된다. 마지막으로 모든 편법을 동원해서 통과시킨 실제 코드를 리팩토링 한다. 리팩토링을 하는 도중에 중간중간 테스트를 실행시켜주면 리팩토링 한 코드가 제대로 동작 하는지에 대한 피드백을 줄 것이다. TDD를 해서 얻는 이점 개발의 라이프 사이클을 많이 단축 시켜준다. 테스트 코드를 통해 프로그램 Spec이 명확해 진다. 리팩토링을 할때 안정감을 준다. 테스트 주도 개발을 하게 되면 위와 같은 이점을 얻을 수 있다. 프로그램을 좀 더 작은 단위로 분리해서 테스트를 진행하기 때문에 라이프 사이클이 단축된다. 예를 들어 백엔드를 개발하고 있다고 가정 해보면 어떤 로직을 테스트하기 위해서 웹 서버를 구동하고 브라우저를 통해 요청을 해서 확인을 하게 되는데 단위 테스틀 이용하면 이러한 과정을 거치지 않고 주요 로직을 검증 할 수 있다. 또한 테스트를 먼저 작성한다는 의미는 곧 프로그램이 어떻게 동작 하는지에 대한 Spec에 대해서 작성한다고 봐도 무방하다. 어떤 Input이 들어 왔을 때 어떤 Output이 기대 되는지 명확히 알 수 있다. 마지막으로 위에서 다뤘던 리팩토링에 대한 “두려움” 을 많이 해소 해준다. 테스트 코드를 먼저 작성하고 통과하도록 변경한 뒤 작성된 테스트에 피드백을 받으면서 점진적으로 코드를 개선해 나갈 수 있다. TDD가 어려운 점 개발 해왔던 방식을 바꾸는 과정에서 익숙 해지는데 시간이 필요 테스트 코드 관리 테스트를 먼저 작성한다는 것은 기존에 개발 해왔던 방식과 많이 다르고 익숙하지 않다. 테스트 코드를 처음 작성할 땐 실제 코드보다 테스트 해야 될 항목을 인지하는 부분과 테스트 코드를 작성하는 부분에 더 많은 시간을 할애하게 될 수 있다. 그리고 테스트 코드 역시 실제 코드와 마찬가지로 리팩토링 해야 되고 관리해야 할 대상이 된다. 따라서 이런 부분은 충분한 연습을 통해서 익숙해진 뒤 실무 코드에 적용 해보는 것이 좋을 것 같다. 충분히 익숙해진 상태라면 테스트 코드를 작성하는 것 자체가 생산성을 떨어뜨릴 것 같지는 않다. 마무리 리팩토링을 하기전에 반드시 테스트 코드를 작성하자 처음 부터 TDD를 적용하기 어렵다면 단위 테스트를 작성하는 걸로 시작하자. 단위 테스트를 작성하는 많은 연습이 필요한 것 같다. Ref https://www.youtube.com/results?search_query=okkycon+2018","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://y0c.github.io/tags/javascript/"},{"name":"tdd","slug":"tdd","permalink":"https://y0c.github.io/tags/tdd/"}]},{"title":"Jenkins x Docker Tomcat War 배포하기","slug":"jenkins-docker-tomcat","date":"2018-10-22T04:00:15.000Z","updated":"2018-10-22T06:30:12.092Z","comments":true,"path":"2018/10/22/jenkins-docker-tomcat/","link":"","permalink":"https://y0c.github.io/2018/10/22/jenkins-docker-tomcat/","excerpt":"","text":"요즘의 소프트웨어 개발은 어떻게 만들까도 많이 고민하지만 어떻게 운영하고 유지보수 할 것인가? 에 대한 고민을 많이 하는것 같다. 어플리케이션 구현보다는 운영에 초점이 맞춰지는 것이다. 소프트웨어 개발을 분석/개발/테스트/배포/운영 의 단계로 나눈다면 배포/운영을 뜻한다. 필자는 생산성에 있어서 굉장히 관심이 많은 편인데 개발을 하면서 지속적으로 느끼는점이 배포/운영에 대한 정확한 프로세스가 정확히 구축되어있지 않으면 추후에 많은 생산성 낭비를 가져올 수 있다는 것이다. Docker를 사용하기 전에는 Maven기반의 프로젝트를 배포할때 보통 Jenkins에서 SCP와 SSH를 통한 배포 혹은 Deploy to Container Plugins , Maven 의 Tomcat 플러그인 등 여러가지 방법을 통해서 배포해왔지만 먼가 부족한 느낌이 들었다.이런방식들 모두 배포하는 서버환경에 의존적이거나 WAS Container에 의존적이기 때문이다. Docker는 DevOps의 도구로 자주쓰이는 도구인 만큼 많은 의존성들을 제거할 수 있고 멱등성(idempotent)을 제공한다. 이번 포스팅은 Maven기반의 프로젝트를 Dockerizing 후 Jenkins를 통해서 배포하는 Workflow 구축에 대해 소개하려한다. Deploy Flow 개발한 내용을 Git, Svn 에 반영한다. Jenkins Workspace로 Pull 을 받는다. Maven 혹은, Gradle과 같은 빌드 도구를 통해 Build를 한다. Docker Image 로 Dockerizing 한다. Private Registry에 Push 해준다. 원격지에서 Image를 Pull 받은 후 Container를 배포한다. (Run) 여기서 5번인 Private Registry는 구지 따로 구축하고 싶지않다면 SSH를 통해서 이미지를 빌드하거나 다른방법을 사용하여도 좋다. 이 글에선 Registry 를 이용한다. Jenkins 설치먼저 Jenkins를 설치해보자. 이번 주제는 Docker를 활용하는 만큼 Docker를 통해서 설치해볼 것이다. Docker를 이용한 설치는 정말 간단하다.12345docker pull jenkins/jenkins:latestdocker run -p 8080:8080 \\ -e TZ='Asia/Seoul' --name jenkins \\ -v ./jenkins:/var/jenkins_home -d 간단하게 사용한다면 이정도만 가지고 실행시키면 된다. 하지만 Jenkins를 Docker로 설치할 경우 Docker 내부에서 Pull &amp; Build가 진행되기 때문에 배포는 모두 Container기준으로 원격지가 된다. 즉 Host OS에 배포하는것도 원격지처럼 배포해야 한다. SSH를 통해서 명령어를 실행시킬수도 있지만 Docker 에서는 TCP Socket을 지원한다.이 TCP Socket을 이용하면 환경변수 지정하는것으로 Remote 에 있는 Docker 명령이 가능해진다. 간단한 예제를 통해서 이해해보자123#!/bin/bashexport DOCKER_HOST=tcp://192.168.0.10:4243docker ps 위 스크립트를 실행하게되면 해당 주소에 있는 docker 프로세스 정보를 보여준다. TCP Socket을 사용하기위해 준비해야할 것들이 있다. Jenkins Container 내부에 Docker가 설치 되어있어야 한다. 배포할 원격지에 TCP Socket이 활성화 되어있어야 한다.Docker - How do I enable the remote API for dockerd 참고 Jenkins 이미지에서 Docker 명령이 가능하도록 Image를 커스터마이징 한다.아래 Dockerfile을 참고하자123456789101112# dind-jenkinsFROM jenkinsci/jenkins:latestUSER rootRUN apt-get update -qqRUN apt-get install -qqy apt-transport-https ca-certificatesRUN apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609DRUN echo deb https://apt.dockerproject.org/repo debian-jessie main &gt; /etc/apt/sources.list.d/docker.listRUN apt-get update -qqRUN apt-get install -qqy docker-engineUSER jenkins 이렇게 docker container 내부에 docker를 설치하는것을 Docker in Docker 라고 한다. 위 파일로 dind-jenkins 이미지를 Build 한 후 필요한 옵션만 넣어서 Run 시킨다.초기에 패스워드를 넣는 창이 나오는데 Docker Container 에 들어가서 확인해야한다.12docker exec -it dind-jenkins /bin/bashcat /var/lib/jenkins/secrets/initialAdminPassword 그 이후에는 플러그인을 설치하고 계정설정을 해주면 된다. Jenkins 설치가 완료됬으면 Pipeline Job을 생성한다.기호에 따라 Maven Job이나 FreeStyle Job을 생성할 수 있지만 최근엔 인프라 설정을 수동으로 설정하는 대신 코드로 관리하는 Infrastructure as Code방식이 많이 쓰이고 있다. 프로젝트 루트에 Jenkins파일과 Dockerfile을 생성한다.Jenkinsfile은 Jenkins Build 설정을 작성해야한다.12345678910111213141516171819202122232425def mvnHomenode &#123; try &#123; stage('Checkout') &#123; checkout scm mvnHome = tool 'M3' &#125; stage('Environment') &#123; sh 'git --version' echo \"Branch: $&#123;env.BRANCH_NAME&#125;\" sh 'docker -v' sh 'printenv' &#125; stage('Push Image') &#123; sh \"'$&#123;mvnHome&#125;/bin/mvn' clean install -P production\" sh('scripts/image.sh') &#125; stage('Deploy') &#123; sh('scripts/deploy.sh') &#125; &#125; catch (err) &#123; throw err &#125;&#125; image.sh 에는 Private Registry에 Push하는 스크립트파일이다.deploy.sh 에는 Private Registry에서 Pull 받은 후 Docker Container 를 run 하는 스크립트 파일이다. 상황에 맞게 골격에 맞춰서 스크립트를 작성해주면 된다. 아래는 war파일을 Docker Image로 Dockerizing 할 수 있는 Dockerfile 이다.123456FROM tomcat:8-jre8WORKDIR /usr/local/tomcatRUN rm -rf ./webapps/*COPY ./target/*.war ./webapps/ROOT.warEXPOSE 8080CMD $CATALINA_HOME/bin/startup.sh &amp;&amp; tail -f $CATALINA_HOME/logs/catalina.out tomcat은 알맞는 jre 버전과 톰캣 버전을 선택해서 Base Image 를 생성하면 된다. 마무리Docker를 활용한 배포는 기존의 방식보다 서버에 대한 의존성에 많은 부분을 제거할 수 있다. Tomcat Manager를 통해서 배포할떈 Out of memory 혹은 jdk 버전의 문제 등 몇가지 이슈가 있었는데 많은부분을 해소해주었다. 다음엔 Docker Swarm을 통한 Container orchestration 관리에 대해 다뤄보려한다.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://y0c.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://y0c.github.io/tags/Docker/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://y0c.github.io/tags/Jenkins/"}]},{"title":"Redis Cluster 구축하기","slug":"redis-cluster","date":"2018-10-21T01:21:57.000Z","updated":"2018-10-23T06:50:10.119Z","comments":true,"path":"2018/10/21/redis-cluster/","link":"","permalink":"https://y0c.github.io/2018/10/21/redis-cluster/","excerpt":"","text":"최근에 구축한 서버환경 중 Session Clustering과 Cache의 용도로 Redis를 사용한 적이 있다.하지만 Redis가 설치된 서버가 한개라 해당 서버가 다운되면 모든 WAS가 서비스를 하지못하는 상황이 나오게 된다.이런 문제때문에 FailOver처리를 위해 Redis Cluster 구축을 생각하게 되었다.이번 포스팅에선 Redis Cluster를 구축하면서 있었던 문제점과 경험담에 대해 공유해보려 한다. Redis 는 기본적으로 손쉽게 Replication을 구성해서 장애대비를 할 수 있다.Master/Slave구조를 갖게되는데 Master는 Read/Write 모두가능하고 Slave는 Read Only이다.상황에 따라서 Read Only Connection만 필요한경우도 있을테지만 이런구조에서는 Master가 Down되면 수동으로Master를 복구해주어야 한다. 이런상황을 막기위한 솔루션으로 Redis Sentinel 과 Redis Cluster 라는 솔루션이 있는데이 두 가지 솔루션중 선택은 상황에 맞게 써주면 좋을 것 같다. Sentinel 에 관해선 따로 포스팅을 작성해 보려한다.이번글에선 Redis Cluster 솔루션에 대해 다뤄보려고 한다. Redis Cluster가 제공하는 기능 Dataset을 여러노드에 분산해서 저장 Auto FailOver( Master - Slave ) 구조를 통해 해결 Redis Cluster TCP PortRedis Cluster는 두개의 TCP Port를 사용하여 통신한다. 기본포트인 6379 혹은 다른포트여도 상관없다.그리고 Node간 통신을 위한포트인 16379 가 사용되는데 이 두 포트 사이의 간격을 10000으로 설정하여 사용한다.자세히 알필요는 없지만 추후에 방화벽 설정에 유의해야한다. Redis x DockerRedis Cluster공식 튜토리얼을 읽어보면 Redis는 Docker의 bridge, 혹은 overlay네트워크를 지원하지 않는다고 작성되어있다. 그래서 기본적으로 Host모드를 사용하라고 한다. 작성하면서 다른글들을 좀 읽어보았는데 Redis 4.0 이상의 버전부터는 cluster-announce-ip, cluster-announce-port, cluster-announce-bus-port를 직접지정할 수 있게되어서 다른 네트워크도 사용이 가능해진것 같다. 여기에 대해 자세한 사항은 아래글을 참고하도록 하자.https://get-reddie.com/blog/redis4-cluster-docker-compose/필자의 경우 Redis Instance를 Host Mode로 사용하고 있다. Try Redis Cluster이제 간단하게 Redis Cluster를 구성해보자. 지금 만들어볼 구조는 Master 3, Slave 3개의 노드를 갖는 Redis Cluster이다. Redis를 설치한다.Source를 받아서 컴파일하는 방식으로 설치할 수 있고, apt와 같은 패키지 매니저로 설치할 수 있다.12345wget http://download.redis.io/releases/redis-4.0.11.tar.gztar -xvf redis-4.0.11.tar.gzcd redis-4.0.11makemake install Redis Cluster에 사용될 Reids Server를 셋팅한다.123mkdir cluster-testcd cluster-testmkdir $(seq 7000 7005) 위와같이 cluster-test 라는 폴더를 만들고 거기에 서버에서 각각사용할 포트별로 폴더를 구성한다.폴더에는 각서버의 config파일과 redis-server executable 파일이 들어가면 된다.config 파일은 redis설치폴더에 그리고 redis-server파일은 src폴더 아래에 존재한다.해당파일을 폴더에 각각 복사하도록 하자. 이때 redis.conf파일에 들어갈 내용은 cluster기본설정만을 포함하고 있다. 123456port 7000cluster-enabled yescluster-node-timeout 5000pidfile /var/run/redis.piddbfilename dump-cluster00.rdbcluster-config-file nodes.conf Redis Server를 실행한다.12# 폴더 별로 들어가서 실행 (귀찮다면 bash script를 하나만들어서 쓰면 된다. )./redis-server ./redis.conf &amp; 여기까지 되었다면 redis-cli 를 통해서 접속이 가능한 상태가 되었다.하지만 아직 cluster로 구성해주지 않았기 때문에 get,set이 불가능하다. cluster를 만드는 도구는 여러가지가 존재한다. redis-cli redis-trib.rb redis-trib.py 이글에선 redis-trib.rb를 통해 만들어보도록 한다.1234567redis-trib.rb create --replicas 1 \\ 127.0.0.1:7000 \\ 127.0.0.1:7001 \\ 127.0.0.1:7002 \\ 127.0.0.1:7003 \\ 127.0.0.1:7004 \\ 127.0.0.1:7005 replicas 1은 master하나당 slave하나라는 의미이다.위 명령어를 실행하면 위에서 부터 3개의 master 그밑으로 3개의 slave로 설정할거냐고 묻는 메시지가 나온다.yes를 누르면 cluster가 구성된다. 접속해서 Test 한다.1redis-cli -p 7000 -c 뒤에 -c옵션은 cluster mode를 의미하므로 반드시 붙여주어야 한다.접속이 정상적으로 이루여젔다면 get, set 명령어를 통해서 dataset의 분산저장 그리고 failover테스트를 할 수 있다. 12set &lt;KEY&gt; &lt;VALUE&gt;get &lt;KEY&gt; set이나 get을 실행하면 어떤 cluster node로 Redirect됬는지 간단하게 나올것이다.그리고 Failover 테스트의 경우 server를 하나씩 내리면서 테스트하면 된다. 필자의 경우 8개의 노드중 6개이상 Down되지않으면 정상적으로 동작하였다. 유의사항Redis Cluster를 사용할땐 Client가 cluster를 지원해야 한다. 필자는 spring환경에서 Jedis Client를 활용하였다.Spring Boot은 간단하게 되어있는데 MVC는 오래되서 마땅한 예제를 찾기 어려웠던 기억이 있다. 마무리간단하게 Redis Cluster를 구축해보고 적용해보았는데 구축자체는 굉장히 간단하지만 여러가지로 생각을 많이 해봤던것같다. Sentinel과 Cluster 사이에서 어떤것을 사용할지 고민했었고 한편으론 Redis의 용도에 비해 과한 아키텍쳐가 아닌가 까지생각을 해봤던것같다. 처음 Redis를 도입하게된 이유도 Session Clustering이나 Cache를 현재 구조에서 가장 적절하게 풀어낼 수 있을거라 생각했는데 관리포인트가 느는건 어쩔수 없는느낌이다. Redis는 Socket, Cache, session등 정말 여러가지 용도로 사용되고 있지만 좀 더 잘 활용할수 있는 밥법도 생각해봐야겠다. 참고 Redis-tutorial Redis 4 with docker-compose","categories":[{"name":"Redis","slug":"Redis","permalink":"https://y0c.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://y0c.github.io/tags/Redis/"}]},{"title":"Docker Private Registry 구축하기","slug":"Docker-Private-Registry","date":"2018-10-20T13:33:51.000Z","updated":"2018-10-20T13:40:25.190Z","comments":true,"path":"2018/10/20/Docker-Private-Registry/","link":"","permalink":"https://y0c.github.io/2018/10/20/Docker-Private-Registry/","excerpt":"","text":"기본적으로 Docker는 Docker Hub라는 공식 Registry를 통해서 이미지를 Push, Pull 할 수 있다.하지만 공개적으로 노출시킬 이미지가 아니라면 Private Registry를 별도로 구축해서 이용해야한다.이번 포스팅에선 Docker Private Registry를 구축하는 방법에 대해 작성해보려 한다.Docker Registry 를 구축하기 위해선 SSL 인증서가 필요하다.만약 인증서를 구매하지 않고 사용하고 싶다면 insecure-registry 를 등록하거나 아니면 Let’s Encrypt 와 같은 무료 TLS솔루션을 찾아보기 바란다.먼저 Docker Registry에 있는 docker-compose 파일을 이용하도록 한다. 123456789101112131415registry: restart: always image: registry:2 ports: - 5000:5000 environment: REGISTRY_HTTP_TLS_CERTIFICATE: /certs/domain.crt REGISTRY_HTTP_TLS_KEY: /certs/domain.key REGISTRY_AUTH: htpasswd REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd REGISTRY_AUTH_HTPASSWD_REALM: Registry Realm volumes: - /path/data:/var/lib/registry - /path/certs:/certs - /path/auth:/auth cert - SSL인증서가 들어갈 디렉토리 auth - htpasswd 계정 정보를 넣어줄 디렉토리 인증서가 준비되었다면 auth/htpasswd 파일을 만들어보자.htpasswd관련 패키지가 설치되어있지 않다면 설치하고 아래 명령을 실행하도록 한다. 1sudo htpasswd -B &lt;파일경로&gt; &lt;만들계정&gt; 명령어를 실행하면 패스워드를 물어보고 계정이 만들어진다. 이제 잘되는지 확인하는 일만 남았다. 1docker-compose up -d docker-compose 를 통해서 container를 데몬으로 띄운다.접속은 브라우저나 curl 원하는 형태로 확인이 가능하다. 1curl -u &lt;계정명&gt;:&lt;패스워드&gt; https://.... 정상적으로 Push, Pull이 되는지 확인해보자 1234docker pull hello-worlddocker tag hello-world &lt;Registry URL&gt;/hello-wrolddocker login &lt;Registry URL&gt;docker push &lt;Registry URL&gt; hello-world Push가 되었다면 &lt;Registry URL&gt;/v2/_catalog 로 접속해서 Repositories 목록에서 확인할 수 있다.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://y0c.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://y0c.github.io/tags/docker/"}]},{"title":"CentOS 7 Mail Server 구축하기 Postfix + Dovecot","slug":"centos7-mail-server","date":"2018-09-28T13:36:10.000Z","updated":"2018-09-28T14:39:00.278Z","comments":true,"path":"2018/09/28/centos7-mail-server/","link":"","permalink":"https://y0c.github.io/2018/09/28/centos7-mail-server/","excerpt":"","text":"메일서버를 구축할일이 생겨서 간단하게 Postfix와 Dovecot개념을 익힐겸 구축해보았다.이번 포스팅은 간단하게 Postfix+Dovecot를 이용해 SMTP, IMAP 서버를 구축하는 과정에대해 작성해보려 한다. 먼저 설치와 셋팅에 앞서서 도메인의 DNS를 먼저 셋팅해주도록 하자.일반적으로 도메인이 example.com 이라면 메일서버는 mail.example.com 서브도메인을 활용하게 된다.mail.example.com 의 A레코드를 먼저 등록한 후 example.com 의 MX레코드를 mail.example.com으로 설정한다. 먼저 yum을 update해준다.yum -y update Postfix완료되었다면 아마 postfix가 설치되어있을 것이다.만약 없을경우 설치해주도록 하자.yum -y install postfix 다음은 ssl인증서를 셋팅한다.(ssl을 이용하지 않는다면 필수사항이 아니다.)12mkdir /etc/postfix/sslcd /etc/postfix/ssl ssl폴더로 이동했다면 openssl 을통해 key,crt 파일을 만든다.1openssl req -x509 -nodes -newkey rsa:2048 -keyout server.key -out server.crt -nodes -days 365 이제 postfix 설정을 수정한다. 1vi /etc/postfix/main.cf 아래 나와있는 설정들을 현재 상황에 맞게 수정하도록 한다.없는부분이 있을시엔 추가하도록 한다.123456789101112131415161718192021222324myhostname = mail.yourdomain.commydomain = yourdomain.commyorigin = $mydomainhome_mailbox = mail/mynetworks = 127.0.0.0/8inet_interfaces = allinet_protocols = allmydestination = $myhostname, localhost.$mydomain, localhost, $mydomainsmtpd_sasl_type = dovecotsmtpd_sasl_path = private/authsmtpd_sasl_local_domain =smtpd_sasl_security_options = noanonymousbroken_sasl_auth_clients = yessmtpd_sasl_auth_enable = yessmtpd_recipient_restrictions = permit_sasl_authenticated,permit_mynetworks,reject_unauth_destinationsmtp_tls_security_level = maysmtpd_tls_security_level = maysmtp_tls_note_starttls_offer = yessmtpd_tls_loglevel = 1smtpd_tls_key_file = /etc/postfix/ssl/server.keysmtpd_tls_cert_file = /etc/postfix/ssl/server.crtsmtpd_tls_received_header = yessmtpd_tls_session_cache_timeout = 3600stls_random_source = dev:/dev/urandom 다음은 master.cf파일을 수정한다. 1vi /etc/postfix/master.cf 아래와 다르게 주석이 되있는부분들은 해제하도록 한다.12345678910111213141516171819202122232425smtp inet n - n - - smtpd#smtp inet n - n - 1 postscreen#smtpd pass - - n - - smtpd#dnsblog unix - - n - 0 dnsblog#tlsproxy unix - - n - 0 tlsproxysubmission inet n - n - - smtpd -o syslog_name=postfix/submission -o smtpd_tls_security_level=encrypt -o smtpd_sasl_auth_enable=yes -o smtpd_reject_unlisted_recipient=no# -o smtpd_client_restrictions=$mua_client_restrictions# -o smtpd_helo_restrictions=$mua_helo_restrictions# -o smtpd_sender_restrictions=$mua_sender_restrictions -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject -o milter_macro_daemon_name=ORIGINATINGsmtps inet n - n - - smtpd -o syslog_name=postfix/smtps -o smtpd_tls_wrappermode=yes -o smtpd_sasl_auth_enable=yes -o smtpd_reject_unlisted_recipient=no# -o smtpd_client_restrictions=$mua_client_restrictions# -o smtpd_helo_restrictions=$mua_helo_restrictions# -o smtpd_sender_restrictions=$mua_sender_restrictions -o smtpd_recipient_restrictions=permit_sasl_authenticated,reject -o milter_macro_daemon_name=ORIGINATING DovecotIMAP/POP3로 이메일을 수신할 수 있도록 Dovecot를 설치하자. 1yum -y install dovecot 이제 설정을 수정하도록 하자.1vi /etc/dovecot/conf.d/10-master.conf smtp-auth를 찾아서 아래와같이 설정한다.123456# Postfix smtp-authunix_listener /var/spool/postfix/private/auth &#123; mode = 0660 user = postfix group = postfix&#125; auth 설정을 수정한다.1vi /etc/dovecot/conf.d/10-auth.conf auth_mechanisms을 찾아서 뒤에 login을 붙여준다. 아마 plain으로 되어있을것이다.12345auth_mechanisms = plain login# 이 설정은 안해주면 계정을 입력할때 Test@example.com 이 아니라 Test로 입력해야 로그인 된다. # 꼭 설정해주도록 하자.auth_username_format = %Ln mail location 을 지정한다.1vi /etc/dovecot/conf.d/10-mail.conf 이 부분은 위에 home_mailbox와 맞춰주어야 한다.제대로 설정되어있지 않으면 나중에 메일수신이 안될 수 있다.1mail_location = maildir:~/mail 다음은 pop3 설정이다.1vi /etc/dovecot/conf.d/20-pop3.conf 아래 라인이 주석처리를 해제한다.1pop3_uidl_format = %08Xu%08Xv 서비스를 재시작해서 모든 설정을 적용한다.1234systemctl restart postfixsystemctl enable postfixsystemctl restart dovecotsystemctl enable dovecot 관련포트를 firewall에 추가해주고 테스트하도록 하자.123456789firewall-cmd --permanent --add-service=smtpfirewall-cmd --permanent --add-port=587/tcpfirewall-cmd --permanent --add-port=465/tcpfirewall-cmd --permanent --add-port=110/tcpfirewall-cmd --permanent --add-service=pop3sfirewall-cmd --permanent --add-port=143/tcpfirewall-cmd --permanent --add-service=imapsfirewall-cmd --permanent --add-service=httpfirewall-cmd --reload 테스트시에는 telnet이나 MXToolbox를 이용하면 된다.간단히 테스트가 성공했다면 Outlook, 혹은 이메일 클라이언트에 연결해서 동작을 확인하면 된다.이메일 클라이언트로 연결시 계정은 기본적으로 리눅스 계정이 공유된다.12345adduser testpasswd test# mail directory # /home/test/mail 간단하게 만들어서 테스트해볼 수 있다. 계정은 이외에도 mysql이나 다른방법으로 관리할 수 있는 것 같다.postfix &amp; mysql 마무리위 과정들이 어렵다면 사실 docker를 이용해서 관련 이미지를 받아서 사용할 수 있다.이미 잘 설정되어있는 이미지들이 조금 검색하면 많이나오는 편이다.하지만 관련설정을 모를시 혼동이 있을 수 있으므로 vm에서라도 간단히 테스트해보면 좋을 것 같다.","categories":[{"name":"Linux","slug":"Linux","permalink":"https://y0c.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://y0c.github.io/tags/Linux/"}]},{"title":"Tmux Tutorial 정리","slug":"tmux-tutorial","date":"2018-09-27T03:18:51.000Z","updated":"2018-09-27T03:23:40.570Z","comments":true,"path":"2018/09/27/tmux-tutorial/","link":"","permalink":"https://y0c.github.io/2018/09/27/tmux-tutorial/","excerpt":"","text":"필자는 Editor중 Vim을 선호하고 주로 사용하는 편이다. Vim을 사용할때 보통 두가지 방법으로 사용하게 된다. IDE 설치후 Vim 플러그인을 통하여 사용 Terminal에서 Vim을 사용 필자는 주로 첫 번째 방법을 통해서 사용하였다.회사에선 주로 Java, Spring계열의 Backend 개발을 하다보니 IDE에 의존적인 기능들이 좀 많았던게 이유이다. 하지만 사이드 프로젝트 개발은 주로 Terminal과 Text Editor로써의 기능을 사용하는 것 같아서 Terminal을 통한 개발환경도 괜찮지 않을까? 라는 생각이들어서 시도해보게 되었다. 이번에 Terminal기반의 Vim 개발환경을 만들때 Tmux라는 것을 알게되었다.이번 포스팅은 Tmux에 대한 간단한 Tutorial 과 사용법을 적어보려 한다./VIm 플러그인이나 사용경험에 대해서는 별도의 포스팅을 작성할 예정이다./ TmuxTmux는 TTY 멀티플렉서 이다. 쉽게 말하자면 하나의 터미널에서 여러개의 터미널로 분할하여 사용할 수 있고. 세션을 생성하여 attach/detach 를 할 수 있다.Mac OS의 ITerm2와 같은 터미널을 사용하게 되면 기본적으로 화면분할을 제공하는데 Tmux는 기본적인 화면분할과 더불어 세션기능을 제공한다.ssh를 통해 원격으로 작업하다가 종료후 재접속 한 후 tmux session에 다시 attach만 해주면 기존의 작업환경을 그대로 사용할 수 있다. 이외에도 단축키와 여러 plugin을 설치해서 사용할 수 있으므로 Mac OS의 ITerm과는 조금 다른 종류라고 보는게 좋을것 같다. 아래 내용에선 Tmux 설치 부터 단축키 Plugin 설치 및 관리방법을 위주로 작성하려한다 InstallationMac OSbrew install tmux Tmux 용어 프리픽스(prefix)단축키입력전에 입력해야하는 키 조합이다. 기본적으로 ctrl + b조합키가 아니라 명령모드 같은 개념이다. 세션(session)Tmux에서 관리하는 가장 큰 단위 윈도우(window)세션에 존재하는 탭 팬(pane)윈도우에 존재하는 화면 단위 Configvi ~/.tmux.conf Reload 시에는tmux source ~/.tmux.conf명령을 통해서 config를 reload 할 수 있다. Shortcut Session 시작123tmux# with session nametmux new -s &lt;session_name&gt; Session 목록1tmux ls Session 종료1234567tmux kill-session -t &lt;session_name&gt;# kill all tmux session tmux ls | grep : | cut -d. -f1 | awk '&#123;print substr($1, 0, length($1)-1)&#125;' | xargs kill# Server shutdowntmux kill-server Session attach1234tmux attach -t &lt;session_name&gt;# or tmux a -t ... 아래 단축키들은 Session attach 후 명령모드에서만 작동한다.즉, prefix(ctrl+a)를 먼저 입력한 후에 아래키들이 동작한다고 보면된다. Session123:new&lt;CR&gt; new sessions list sessions$ name session Window1234567c create windoww list windowsn next windowp previous windowf find window, name window&amp; kill window Panes(Splits)1234567891011121314% vertical split\" horizontal splito swap panesq show pane numbersx kill pane+ break pane into window (e.g. to select text by mouse to copy)- restore pane from window⍽ space - toggle between layouts&lt;prefix&gt; q (Show pane numbers, when the numbers show up type the key to goto that pane)&lt;prefix&gt; &#123; (Move the current pane left)&lt;prefix&gt; &#125; (Move the current pane right)# 하나의 팬을 전체화면으로 유용하게 사용&lt;prefix&gt; z toggle pane zoom PluginTmux는 다양한 Plugin으로 커스터마이징이 가능하다. 구글링을 좀 해보면 상태바를 이쁘게 만드는 방법이나 키매핑을 편리하게해주거나 등 다양한 플러그인이 있으니 찾아보면 된다. 여기선 기본적으로 플러그인을 설치하는 방법만 적어보려한다.먼저 패키지 매니저인 TPM을 설치한다. 설치가 정상적으로 됬다면 그후론 ~/.tmux.conf 에 설치할 플러그인 목록을 작성한후 &lt;prefix&gt; + I 로 설치할 수 있다. 자세한내용은 TPM repo의 README를 참고하도록 하자. 필자가 사용중인 플러그인 목록이다. tmux-resurrect tmux-cpu-mem-load tmux-pane-control 참고https://blog.outsider.ne.kr/699https://www.haruair.com/blog/2124https://gist.github.com/MohamedAlaa/2961058https://bluesh55.github.io/2016/10/10/tmux-tutorial/ 마무리그냥 터미널에서 Vim을 좀 더 편하게 사용해보려고 시작했지만 이외의 용도로도 유용하게 사용할 수 있을것같다. 꼭 vim과 같이 사용하지 않더라도 서버에 깔아두거나 mac에서 사용하기에 장점이 많은 것 같다. 페어프로그래밍에도 쓰일 수 있다는데 기회가 되면 해보고 싶다.","categories":[{"name":"Tmux","slug":"Tmux","permalink":"https://y0c.github.io/categories/Tmux/"}],"tags":[{"name":"tmux","slug":"tmux","permalink":"https://y0c.github.io/tags/tmux/"}]},{"title":"Semantic-Ui-React Theme Customizing","slug":"semantic-ui-react-theme","date":"2018-09-10T12:38:56.000Z","updated":"2018-09-10T12:41:50.676Z","comments":true,"path":"2018/09/10/semantic-ui-react-theme/","link":"","permalink":"https://y0c.github.io/2018/09/10/semantic-ui-react-theme/","excerpt":"","text":"semantic-ui-react는 semantic-ui 를 react로 구현한 라이브러리이다.react로 프로젝트를 하게되면 ui kit으로 semantic-ui-react를 많이 사용되고 있다. 한 번 사용해본 후기로는 다양한 형태의 UI Component를 지원해서 UI를 구현하는데 걸리는 시간을 많이 단축시켜 생산성을 올려준다. 하지만 사용하다 보면 테마를 변경해야하거나 Component Style을 변경하고 싶을때가 있다. 이 글에선 create-react-app 으로 생성한 react app에서 semantic-ui-react 테마를 커스터마이징 해본 경험을 공유해보고자 한다. 공식 메뉴얼에도 테마 커스터마이징에 대해서 두가지 방법으로 소개하고 있다. Semantic-UI-Less project를 받아서 Customizing 하는 방법 Webpack2 와 연동 하여 Customizing 하는 방법 첫 번째 방법은 create-react-app 을 통해서 프로젝트를 만들었을경우 따로 프로젝트를 만들어서 컴파일 한 후 css파일을 옮겨야 하기 때문에 굉장히 번거로울 수 있다.이 글에선 두 번째 방법을 기준으로 설명하려 한다. 거이 대부분의 가이드는 위 가이드 문서에 잘 작성되어 있다.단, create-react-app 환경에선 몇가지 이슈가 있었다. 먼저 create-react-app 환경이라면 yarn run eject 명령을 통해서 webpack 설정을 커스터마이징 해야한다. semantic-ui-less 모듈을 설치한다.1yarn add semantic-ui-less 테마를 커스터마이징 하기 위해서 설치된 기본 테마와 설정을 로컬로 복사해와야한다.위 문서에는 root폴더 아래에 theme폴더를 만들라고 권장하고 있지만 create-react-app 구조에서는 src폴더 아래에 theme 폴더를 만들어주면 된다. theme 폴더는 site폴더와 theme.config 설정파일을 만들어주도록 하자. config파일은 node_modules/semantic-ui-less/theme.config.example 복사해서 생성 site폴더는 node_modules/semantic-ui-less/site/default아래 폴더 모두 복사 여기까지 됬다면 theme.config 파일의 variable을 현재 설정에 맞춰줘야 한다. @import &quot;theme.less&quot;; 부분을 @import (multiple) &quot;~semantic-ui-less/theme.less&quot;; 와 같이 수정한다. @siteFolder : &quot;site&quot;; 부분을 @siteFolder : &quot;../../src/styles/semantic/theme/site&quot; 와 같이 수정한다. 여기서 siteFolder는 현재 site폴더의 경로이다. (필자는 /src/styles/semantic/theme/site 로 설정되어 있다) config 파일의 마지막 라인에 @fontPath : &quot;../../../themes/@{theme}/assets/fonts&quot;;를 추가해주도록 한다. theme config 파일 설정을 마치면 아래와 같이 webpack alias를 추가하도록 한다.참고로 create-react-app 으로 설정할시 __dirname은 script폴더이므로 아래 필자와 같이 설정하도록 한다.1234567alias: &#123; '../../theme.config$': path.join(__dirname, '../src/styles/semantic/theme/theme.config'), // Support React Native Web // https://www.smashingmagazine.com/2016/08/a-glimpse-into-the-future-with-react-native-for-web/ 'react-native': 'react-native-web', &#125;, 다음으론 webpack환경에서 less를 compile하기 위해서 아래와 같이 css-loader, less-loader, extract-text-plugin을 설치한다. extract-text-plugin은 production에만 적용해주면되는데 아래와같이 모두 less-loader만 추가해주면 된다.1yarn add --dev less css-loader less-loader extract-text-webpack-plugin 12345678910111213141516171819202122232425262728293031&#123; test: /\\.css$|\\.less$/, use: [ require.resolve('style-loader'), &#123; loader: require.resolve('css-loader'), options: &#123; importLoaders: 1, &#125;, &#125;, &#123; loader: require.resolve('postcss-loader'), options: &#123; // Necessary for external CSS imports to work // https://github.com/facebookincubator/create-react-app/issues/2677 ident: 'postcss', plugins: () =&gt; [ require('postcss-flexbugs-fixes'), autoprefixer(&#123; browsers: [ '&gt;1%', 'last 4 versions', 'Firefox ESR', 'not ie &lt; 9', // React doesn't support IE8 anyway ], flexbox: 'no-2009', &#125;), ], &#125;, &#125;, &#123; loader : 'less-loader'&#125; 맨아래줄에 less-loader를 추가해준다. 참고로 create-react-app의 경우 아래와같은 설정이 있는데 이부분을 주석으로 막아야 정상적으로 동작한다.. 1234567891011&#123; // Exclude `js` files to keep \"css\" loader working as it injects // its runtime that would otherwise processed through \"file\" loader. // Also exclude `html` and `json` extensions so they get processed // by webpacks internal loaders. exclude: [/\\.(js|jsx|mjs)$/, /\\.html$/, /\\.json$/], loader: require.resolve('file-loader'), options: &#123; name: 'static/media/[name].[hash:8].[ext]', &#125;,&#125;, 위부분을 막고 아래내용으로 대체해주도록 하자. 1234567891011121314151617181920&#123; test: /\\.jpe?g$|\\.gif$|\\.ico$|\\.png$|\\.svg$/, use: 'file-loader?name=[name].[ext]?[hash]'&#125;,// the following 3 rules handle font extraction&#123; test: /\\.woff(2)?(\\?v=[0-9]\\.[0-9]\\.[0-9])?$/, loader: 'url-loader?limit=10000&amp;mimetype=application/font-woff'&#125;,&#123; test: /\\.(ttf|eot)(\\?v=[0-9]\\.[0-9]\\.[0-9])?$/, loader: 'file-loader'&#125;,&#123; test: /\\.otf(\\?.*)?$/, use: 'file-loader?name=/fonts/[name]. [ext]&amp;mimetype=application/font-otf'&#125; 마무리less버전에 따라 이슈가 발생할 수 있다.필자는 2.7.3 버전에서 정상적으로 작동하는걸 확인하였다. 관련 이슈는 아래링크에서 확인하도록 하자.Make LESS 3.x compatible · Issue #30 · Semantic-Org/Semantic-UI-LESS · GitHub SemanticUI는 Component 종류도 다양하고 사용에도 용이하다.단 전혀 손을대지않으면 폰트사이즈나 간격등이 크거나 맞지않을 수 있기때문에커스터마이징하는 방법에 대해 기록해본다.","categories":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/categories/React/"}],"tags":[{"name":"react","slug":"react","permalink":"https://y0c.github.io/tags/react/"},{"name":"semantic-ui-react","slug":"semantic-ui-react","permalink":"https://y0c.github.io/tags/semantic-ui-react/"}]},{"title":"Javascript Closure란?","slug":"js-closure","date":"2018-09-09T19:50:35.000Z","updated":"2018-09-09T21:33:25.200Z","comments":true,"path":"2018/09/10/js-closure/","link":"","permalink":"https://y0c.github.io/2018/09/10/js-closure/","excerpt":"","text":"javascript 를 공부하다보면 closure라는 개념을 자연스럽게 접하게 된다.이번 포스팅에선 Closure에 대해서 좀 더 깊게 다뤄보려고 한다. Closure 개념에 앞서서 먼저 함수에 대해서 언어별로 처리하고 있는 방법에 대해서 논해보도록 하자. 함수는 언어별로 사용되는 형태의 차이가 있다.예를들면, Java와 같은 언어에서는 함수(메소드)를 문(Statement) 처럼 취급한다.다른 예를보면 C, Javascript, Python, Kotlin, Swift 와 같은 언어를 보면 함수도 일반적인 값(Value)처럼 취급한다. 1급 객체(first-class citizens)1급 객체는 일반적으로 위에서 설명한 함수를 값(Value)처럼 취급하는 언어들에 해당된다. 1급 객체의 조건은 다음과 같다. 변수나 데이터 구조안에 담을 수 있다. 파라미터로 전달할 수 있다. 반환값으로 사용할 수 있다. 여기서 런타임 시에 함수를 생성할 수 있는지 여부에 따라 2급 객체 로 분류하기도 한다. 함수를 1급 객체로 다루는 언어들의 특징함수를 1급 객체로 다루는 언어들의 특징에 대해서 잠시 알아보자. 런타임시에 동적으로 함수를 생성가능 ex) lambda 함수를 값(Value)로 취급 함수가 생성된 환경을 기억하고 있다. 아래 간단한 예시를 보자12345678910111213function makeFunc() &#123; //자유변수(Free Variable) var name = 'Mozilla'; //Closure function displayName() &#123; //지역변수(Local Variable) var v1 = 'test'; alert(name); &#125; return displayName;&#125; 함수가 런타임시에 동적으로 함수를 생성하는 예제이다.여기서 몇가지 개념에 대해 정리하려고 한다.런타임시에 함수를 생성할 수 있는 언어들은 생성된 환경(Context)를 기억하고 있다.함수를 문(Statement)으로 취급하는 언어들은 기본적으로 Global 과 local영역을 참조했다면 참조할 영역이 늘어난 셈이다. displayName 함수 입장에서 상위 함수인 makeFunc의 name도 참조할 수 있어야한다. 여기서 local영역이 아닌 상위 함수의 변수들을 자유변수(Free Variable) 이라고 한다. 그리고 이 자유변수들을 가르키는 함수가 Closure이다. 위 예제에서는 name 자유변수를 사용하고 있는 displayName이 Closure Context 함수가 생성된 환경 Javascript에서는 Lexical Environment라고도 한다. 자유변수(Free Variable) local영역이 아닌 Context 영역의 변수들즉, local에 존재하지 않는 모든 변수를 뜻함 Closure 독립적인 자유변수를 가리키는 함수(자유변수를 가두는 영역) 정리하자면, Closure란 JS에 국한된 개념이 아니라 런타임에 함수가 만들어지는 언어에서는 자유변수 라는 개념이 존재하고 자유변수가 존재하면 필연적으로 Closure 가 발생하게 된다. Closure와 성능일반적으로 함수의 지역변수는 함수가 끝남과 동시에 메모리에서 해제된다.클로저는 위에서 언급했듯이 함수가 생성된 환경(Context)을 기억하고 변수(자유변수)를 참조할 수 있다. 그리고 자유변수를 한 번 이라도 참조했다면 메모리에서 해제되지 않는다. 그러므로 Closure가 필요하지 않은 상황에서 함수내에 함수를 작성하는것은 메모리 소비 측면에서 부정적인 영향을 미친다. Closure와 ScopeES6이전의 JS에서는 오직 function만의 새로운 scope를 생성했다.아래 예시를 보도록 하자.123456789101112131415161718function showHelp(help) &#123; document.getElementById('help').innerHTML = help;&#125;function setupHelp() &#123; var helpText = [ &#123;'id': 'email', 'help': 'Your e-mail address'&#125;, &#123;'id': 'name', 'help': 'Your full name'&#125;, &#123;'id': 'age', 'help': 'Your age (you must be over 16)'&#125; ]; for (var i = 0; i &lt; helpText.length; i++) &#123; var item = helpText[i]; document.getElementById(item.id).onfocus = function() &#123; showHelp(item.help); &#125; &#125;&#125; 대충 훑어보기에는 코드에 문제가 없어보일 수 도 있다.하지만 위 코드는 의도한대로 작동하지 않는다. 모두 age에 관한 도움말을 보여주게된다.코드를 분석해보면 onfocus에는 클로저가 연결되어있다. loop문을 통해 3개의 클로저가 생성되지만 하나의 자유변수(item)를 공유하기 때문이다.(var은 scope 범위가 함수이기 때문에) 해결방법은 클로저를 하나더 생성하는 것이다.클로저를 하나 더 생성함으로 동일한 item이 아닌 각각 다른 item을 가리키게 된다.1234567for (var i = 0; i &lt; helpText.length; i++) &#123; (function(item)&#123; document.getElementById(item.id).onfocus = function() &#123; showHelp(item.help); &#125; &#125;)(helpText[i])&#125; 위와같은 방법이 좀 복잡하다고 느껴진다면 let을 사용하도록 하자.let은 유효범위가 block 즉, 중괄호 이므로 클로저를 추가적으로 만들지 않아도 의도한대로 동작하게 된다. 참고https://developer.mozilla.org/ko/docs/Web/JavaScript/Guide/Closures","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://y0c.github.io/categories/Javascript/"}],"tags":[{"name":"Closure","slug":"Closure","permalink":"https://y0c.github.io/tags/Closure/"},{"name":"javascript","slug":"javascript","permalink":"https://y0c.github.io/tags/javascript/"}]},{"title":"JS의 Generator와 Iterator","slug":"js-generator","date":"2018-09-09T08:43:24.000Z","updated":"2018-09-09T13:48:13.240Z","comments":true,"path":"2018/09/09/js-generator/","link":"","permalink":"https://y0c.github.io/2018/09/09/js-generator/","excerpt":"","text":"ES6의 Generator와 Iterator이번 포스팅에선 ES6의 Generator와 Iterable, Iterator에 대해서 다뤄보려고 한다. Generator를 살펴보기 전에 먼저 Iterable과 Iterator에 대해서 이해하고 넘어가도록 하자. 사실 요즘 왠만한 언어들은 반복(loop)에 대해서 추상화된 방법과 인터페이스를 제공하고 있다. Java를 예로들면 Iterator라는 인터페이스를 제공하고 있다. 이런식의 반복(loop)을 추상화된 인터페이스로 제공할경우 얻을 수 있는 장점은 내장반복이 있는 Array나 Map 과 다르게 사용자 정의 Object나 기본 반복동작이 없는 객체들도 for...of 문으로 동일하게 반복을 정의할 수 있다는 것이다. Iteratoriterator 인터페이스는 반복에 대한 표준화된 방법을 제공한다.구현 방법은 아래와 같다. next() 메소드를 구현 next() 메소드는 IteratorResultObject를 리턴 IteratorResultObject done 과 value를 갖는 객체.여기서 done은 반복의 완료여부 value는 현재 값을 의미 아래 예시는 배열을 인자로 받아서 반복하는 iterator 예시이다.12345678910111213141516//iter 함수는 iterator object를 리턴 const iterator = data =&gt; (&#123; data, next() &#123; return &#123; done: this.data.length == 0, value: this.data.pop() &#125; &#125;&#125;)const arrayIterator = iterator([1,2,3]);console.log(arrayIterator.next().value) // 3console.log(arrayIterator.next().value) // 2console.log(arrayIterator.next().value) // 1 Iterator 만으로는 for…of 구문을 사용할 수 없다.직접 반복에 대한 처리기를 구현해서 사용하거나 추가적으로 Iterable과 같이 사용하여야 한다. Iterableiterable 인터페이스를 구현하면 반복이 가능한 객체를 의미한다.즉, 이 iterable 인터페이스를 구현하면 for...of 문을 통해 반복문을 작성할 수 있게된다.인터페이스 구현은 단지 Symbol.iterator메소드를 만들어주면 된다. 단, 여기서 Symbol.iterator 메소드는 반드시 iterator object를 반환해야 한다. 아래 예시를 보고 좀 더 정확히 이해하도록 하자.123456789101112131415161718const iter = data =&gt; (&#123; //key는 @@iterator로 대체가 가능하다. [Symbol.iterator]()&#123; // iterator object를 반환 return &#123; data, next() &#123; return &#123; done: this.data.length == 0, value: this.data.pop() &#125; &#125; &#125; &#125;&#125;) for(const a of iter([1,2,3])) console.log(a); 위 iterator예제에 추가적으로 iterable 인터페이스를 구현하였다. 이 결과로 내장 반복처리기의 사용이 가능해진다. 내장반복처리기 Array destructuring Spread Rest Parameter For…of Generatorgenerator는 일반적으로 iterator를 쉽게 구현하기 위해 나온 문법으로 알고있다. 하지만 ES6의 generator는 단지 iteraotr를 쉽게 만들어주는 역활만을 한다고 보기는 어렵다. 먼저 코루틴 이라는 개념에 대해 알아보도록 하자. 코루틴 일반적인 함수(루틴)은 Main Flow로 부터 단순히 값을 인자로 받아서 return으로 종료된다. 여기에 return 과 더불어 suspend/resume 기능을 실행할 수 있게해준다. 즉 중단을 걸고 중단된 지점부터 실행을 이어갈 수 있다. generator 문법은 iterator를 통해서 이러한 코루틴을 만들어주는 역활을 한다. yield키워드를 통해서 suspend를 걸 수 있다. next()가 호출되면 resume된다. 위에서 만들었던 예제를 generator로 바꾸면 아래와같이 변경할 수 있다.12345678910const iter = data =&gt; (&#123;//key는 @@iterator로 대체가 가능하다. *[Symbol.iterator]()&#123; let v; while(v=data.pop()) yield v; &#125;&#125;) for(const a of iter([1,2,3])) console.log(a); iterator 를 직접 구현했을 때보다 훨씬 간결하고 편리하게 작성할 수 있다. 이러한 generator 의 사용은 iterator 인터페이스의 구현을 도와주기도 하지만 비동기 코드를 다룰때 매우 유용히 사용할 수 있다. 아래 예시를 보도록 하자123456789101112131415161718192021222324252627282930313233class User &#123; constructor(name, age)&#123; this.name = name; this.age = age; &#125;&#125;const users = [ new User('tony',10), new User('john',20), new User('jang',30)]; const findUser = name =&gt; new Promise((resolve,reject) =&gt; &#123; setTimeout(_ =&gt; &#123; resolve(users.find(v =&gt; v.name == name)); &#125;,1000);&#125;);const submit = user =&gt; new Promise((resolve,reject) =&gt; &#123; setTimeout(_ =&gt; &#123; resolve(&#123; success : true &#125;); &#125;,2000)&#125;);const generator = function*() &#123; let user = yield findUser('tony'); user.name = 'test'; let result = yield submit(user); console.log(result);&#125; 일반적으로 회원을 찾아서 수정한 후 submit하는 코드이다.db를 따로 구현하지 않고 setTimeout 과 Promise 를 통해Fake API를 만들었다. generator를 사용하면 위 예제의 generator 함수와 같이 비동기적인 코드를 동기식으로 표현할 수 있게된다.단, promise를 처리하는 반복처리기를 직접 구현해야한다. 처리기의 내용은 다음과 같다.1234567891011121314151617const promiseIterator = function(gen) &#123; const iterator = gen(); function run(arg) &#123; const result = iterator.next(arg); if( result.done ) &#123; return result.value; &#125; else &#123; return Promise.resolve(result.value).then(run); &#125; &#125; return run();&#125;// 이처럼 사용이 가능하다. promiseIterator(generator()) 이 처리기는 간단하게 promise 반복처리기를 구현한 내용이다.실제 사용은 Co 와 같은 라이브러리를 사용해서 처리하도록 하자. 이러한 generator를 통한 비동기제어는 promise 처리기를 따로 구현하지 않아도 ES7의 async/await syntax를 통해서 좀 더 편리하게 사용할 수 있다. 참고Iteration protocols - JavaScript | MDN반복기 및 생성기 - JavaScript | MDN","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://y0c.github.io/categories/Javascript/"}],"tags":[{"name":"ES6","slug":"ES6","permalink":"https://y0c.github.io/tags/ES6/"},{"name":"generator","slug":"generator","permalink":"https://y0c.github.io/tags/generator/"},{"name":"iterator","slug":"iterator","permalink":"https://y0c.github.io/tags/iterator/"},{"name":"Javascript","slug":"Javascript","permalink":"https://y0c.github.io/tags/Javascript/"}]},{"title":"Javascript Decorator Pattern","slug":"js-decorator","date":"2018-08-10T13:43:13.000Z","updated":"2018-09-09T21:35:06.058Z","comments":true,"path":"2018/08/10/js-decorator/","link":"","permalink":"https://y0c.github.io/2018/08/10/js-decorator/","excerpt":"","text":"Decorator Pattern의 사전적 정의는 아래와 같다. 주어진 상황 및 용도에 따라 어떤 객체에 특성 혹은 행동을 덧붙이는 패턴 서브클래싱 보다 좀 더 유연한 기능확장을 할 수 있도록 대안으로 쓰임앞서 학습한 Builder Pattern에서는 원하는 속성만 셋팅해서 손쉽게 원하는 객체를 만들어냈다면 Decorator Pattern 을 사용한다면 OCP 원칙에 어긋나지 않게 객체를 원하는기능만 손쉽게 추가할때 용이하다. 먼저 일반적인 Decorator Pattern의 예제를 보자.아래 예제는 Head First 책에서 나오는 예제를 조금 변형해서 Javascript로 작성한 것이다.( 코드 가독성을 위해 ES6 Syntax 로 작성하였다.) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Coffee &#123; getCost() &#123; return 1.0; &#125; getIngredients() &#123; return \"Coffee\"; &#125;&#125;class CoffeeDecorator extends Coffee &#123; constructor(decoraterCoffee) &#123; super(); this.decoraterCoffee = decoraterCoffee; &#125; getCost() &#123; return this.decoraterCoffee.getCost(); &#125; getIngredients() &#123; return this.decoraterCoffee.getIngredients(); &#125; toString() &#123; return `Cost : $&#123;this.getCost()&#125; , Ingredients : $&#123;this.getIngredients()&#125;`; &#125;&#125;class Milk extends CoffeeDecorator &#123; getCost() &#123; return super.getCost() + 0.5; &#125; getIngredients() &#123; return super.getIngredients() + \", Milk\"; &#125;&#125;class Cream extends CoffeeDecorator &#123; getCost() &#123; return super.getCost() + 0.7; &#125; getIngredients() &#123; return super.getIngredients() + \", Cream\"; &#125;&#125;let coffee = new Coffee();let caffeLatte = new Milk(coffee);let caffeMocha = new Cream(milkCoffee);//Inline-Style// let milkCreamCoffee = new Cream( new Milk( new Coffee() ) );console.log(caffeLatte.toString()); // Print -&gt; Cost : 1.5 , Ingredients : Coffee, Milkconsole.log(caffeMocha.toString()); // Print -&gt; Cost : 2.2 , Ingredients : Coffee, Milk, Cream 위 예제는 주어진 재료를 가지고 다양한 형태의 커피를 만드는 예제이다.만약 클래스의 상속을 통해 위 기능을 구현하려 한다면 CaffeeLatte, CaffeeMocha 등커피의 종류가 늘어날수록 클래스를 추가해주어야 할 것이다. 데코레이터 패턴을 적용한다면 위와같이 재료를 정의해놓고 커피를 만들때 필요한 것들만 유연하게 추가하여 커피를 제조할 수 있게된다. Javascript 에서의 Decorator Pattern자바스크립트는 함수형 프로그래밍이 가능하기 때문에 고차 함수(Higher-Order Function)을 통한 Decorator 구현이 가능하다. 실제로 많은 라이브러리나 프레임워크에서도 이와같은 패턴으로 많이 사용되고 있다. 예를 들자면 최근에 React의 Higher Order Component나물론 Express의 Middleware 같은 경우 Decorator Pattern 과 Chain-Of-Responsibility 가 조합된 형태이다. Higher-Order Function 을 이용한 Decoractor 예제123456789101112131415161718192021222324function ajaxRequest(url, method, data) &#123; console.log(`request -&gt; $&#123;url&#125; , $&#123;method&#125;, $&#123;data&#125;`);&#125;function loggerDecorator(func) &#123; return (...args) =&gt; &#123; console.log('Start'); console.log(`Argument : $&#123;args.join(' , ')&#125;`); const result = func.apply(this, args); console.log('End'); return result; &#125;&#125;const request = loggerDecorator(ajaxRequest);request('http://www.naver.com', 'get', 'query=test');//Output//Start//Argument : http://www.naver.com , get , query=test//request -&gt; http://www.naver.com , get, query=test//End 위 예제처럼 ajaxRequset를 하는 함수에 logging을 해주는 decorator를 추가한 예제이다. 이 예제는 정말 간단한 예제이지만 매우 유용하게 사용될 수 있다.전처리, 후처리 공통된 작업을 Decorator를 통해 추가할 수 있고 기능을 손쉽게 확장할 수 있다. ES7 DecoratorECMAScript2016(ES7) 스펙에 추가된 것 중 Decorator라는 문법이 새로 제안되었다. 이 Decorator 문법은class, function, property 모두 어떤 특성이나 행동을 쉽고 깔끔하게 덧붙일 수 있다. 위에서 고차함수를 통해 구현했던 Decorator를 ES7의 Decorator 문법을 통해 아래와 같이 변경해 볼 수 있다.(아래 예제는 log 이외에 권한체크를 하는 decorator를 추가로 구현했다)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899//log Decoratorfunction log(name) &#123; return function (target, name, descriptor) &#123; const func = descriptor.value; descriptor.value = (...args) =&gt; &#123; console.log('Start'); console.log(`Argument : $&#123;args.join(' , ')&#125;`); const result = func.apply(this, args); return result; &#125; &#125;&#125;//Fake Authconst AuthUtil = &#123; isAuth: () =&gt; &#123; return false; &#125;, roleCheck: (role) =&gt; &#123; let currentUserRole = 'admin'; return role === currentUserRole; &#125;&#125;// Authentication Decoratorfunction Authentication(&#123; isAuth, role&#125;) &#123; return (target, name, descriptor) =&gt; &#123; const func = descriptor.value; descriptor.value = (...args) =&gt; &#123; if (isAuth) &#123; if (!AuthUtil.isAuth()) &#123; throw new Error('Unauthorized Error!!!'); &#125; &#125; if (role) &#123; if (!AuthUtil.roleCheck(role)) &#123; throw new Error('Unauthorized Error!!!'); &#125; &#125; return func.apply(this, args); &#125; &#125;&#125;class Router &#123; @log('index page') index() &#123; console.log('request -&gt; index'); &#125; @log('login page') login() &#123; console.log('request -&gt; login'); &#125; @log('admin page') @Authentication(&#123; isAuth: true, role: 'admin' &#125;) admin() &#123; console.log('request -&gt; admin'); &#125;&#125;const router = new Router();try &#123; router.index('test', 'test2'); router.admin('request admin page...');&#125; catch (e) &#123; console.log(e.message);&#125;//Output /*StartArgument : test , test2request -&gt; indextestStartArgument : request admin page...Unauthorized Error!!!*/ 이 글에선 ES7 Decorator에 대해 자세히 내용을 다루진 않는다.( 파라미터에 대한 설명등은 babel 이나 mdn을 참조하도록 하자) Decorator 자체는 함수이고 이 함수는 원래 함수를 변형시켜 새로운 함수를 만들어서 리턴한다. 아마 위에 Decorator Pattern에 대해 이해했다면 어렵지 않게 이해할 수 있을거라고 생각한다. 위 예제와 같이 logging, auth check, parameter check 등 공통적으로 분리하기 어려운 관심사(Cross-Cutting Concern) 을 깔끔하게 분리해서 구현하고 사용할 수 있다. 최근 React에서도 HOC와 Decorator를 조합해서 위와 비슷한 패턴으로 많이 사용되고 있다고 한다. 추후에 이 조합에 대해서도 다뤄봐야 될 것 같다. 참고ES7의 Decorator문법은 아직 제안 상태이므로 babel 과 함께 사용하여야 정상적으로 작동한다. [링크]Decorators transform · Babel","categories":[{"name":"Javascript","slug":"Javascript","permalink":"https://y0c.github.io/categories/Javascript/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://y0c.github.io/tags/javascript/"},{"name":"design-pattern","slug":"design-pattern","permalink":"https://y0c.github.io/tags/design-pattern/"}]},{"title":"Serverless Koa기반 Api Server 배포하기","slug":"serverless-koa","date":"2018-07-28T15:37:00.000Z","updated":"2018-09-09T21:35:17.884Z","comments":true,"path":"2018/07/29/serverless-koa/","link":"","permalink":"https://y0c.github.io/2018/07/29/serverless-koa/","excerpt":"","text":"이 포스팅에선 aws lambda와 serverless framework를 통해서 koa 기반의 api server를 배포하는 것에 대해 소개하려한다.전체적인 배포 과정을 나열하기보다는 간략한 소개와 boilerplate로 어떤식으로 접근하는지에 중점을 두었다. 필자가 처음 lambda를 접했을땐 토픽별 기능(크롤링, 이미지처리) 이나 AWS와 연계된 서비스에서 모니터링 혹은 알림 같은 곳에 사용할때 유용한 정도로만 생각하고 있었다.lambda에서는 node.js, phtyon, java 등과 같은 여러가지 언어를 제공하고 있지만실제로 api server를 통째로 lambda를 이용하기엔 오히려 불편한점이 꽤 많아 보였기 때문이다. 아래 코드는 AWS lambda 에서 제공하는 nodejs 예시 코드이다.1234567exports.myHandler = function(event, context, callback) &#123; console.log(\"value1 = \" + event.key1); console.log(\"value2 = \" + event.key2); callback(null, \"some success message\"); // or // callback(\"some error type\"); &#125; 위 코드가 하나의 function 즉 endpoint가 된다.단순한 하나의 function 이 아닌 api server를 개발하려면 수 많은 lambda function을 만들어야하기 떄문에 구조가 굉장히 난해해 보였다. 지금껏 express, koa, hapi 와 같은 프레임워크를 통해 backend 개발을 해왔다면 위구조에서 어떤식으로 사용해야될지 잘 감이 오지 않을것이다. 최근에 지인을 통해 serverless-http 모듈에 대해 듣고 잠시 접해볼기회가 있었는데serverless-http는 lambda에 대한 약간의 이해만 있으면 기존에 express나 koa를 통해서 API를 쉽게 Wrap해서 배포할 수 있게된다.실제로 사용해본 경험으론 serverless-http를 사용하게되면 간단한 설치와 몇라인으로 wrapping 할 수 있었다.모듈에대한 자세한 설명은 해당 Repo를 참고하도록 하자.GitHub - dougmoscrop/serverless-http: Use your existing middleware framework (e.g. Express, Koa) in AWS Lambda 🎉 이제 본격적으로 koa 기반 api-server 를 lambda에 배포하는 작업을 해보자.이 작업을 하기위해선 AWS계정과 Serverless 계정이 필요하다.Serverless - The Serverless Application Framework powered by AWS Lambda, API Gateway, and morehttps://aws.amazon.com/ko/ AWS는 계정을 만든후 IAM을 통해 user를 만든후 access_key 와 secret_key가 필요하다. 이 과정에 대해선 아래 글에 자세히 설명되있으니 참조하도록 하자.serverless/credentials.md at master · serverless/serverless · GitHub 먼저, serverless 를 설치한다.npm install -g serverless 아래 명령어는 aws nodejs용 템플릿을 만들어주는데 틀을 보고 필요한 부분은 찾아서 작성하도록한다.serverless create -t aws-nodejs koa기반 app 을 배포할것이기 때문에 serverless-http 모듈도 설치하도록 하자.npm install serverless-http 여기까지 됬다면 기본적인 앱을 배포하는데 기본적인 준비가 끝난 것이다.기존 koa app을 개발하는 구조와 동일하게 사용하여도 무방하다.serverless 배포를 위해 작성해야될 코드는 아래가 전부이다.12345import serverless from 'serverless-http';import app from 'app';// handler는 serverless yml 파일에서 지정해준 이름을 사용하여야한다. export const handler = serverless(app); app을 배포할때는 sls deploy —stage &lt;stage_name&gt; 을 통해서 배포할 수 있다. 사용해본 후기로 생각보다 간단하게 koa 혹은 express app을 lambda로 배포할 수 있었다. 앞으로도 간단한 api server 를 구성할때 자주 사용하게 될 것 같다. express 기반 boilerplate는 검색하면 바로나오는 편인데 koa 관련해서는 boilerplate가 적당한게 보이지않아서 연습하면서 간단하게 boilerplate를 구성해보았다. GitHub - y0c/serverless-koa-boilerplate: Serverless-http with Koa Boilerplate ES6/7 Syntax를 사용할 수 있도록 babel 과 serverless-webpack 관련 설정을 추가된 boilerplate 이다.","categories":[{"name":"serverless","slug":"serverless","permalink":"https://y0c.github.io/categories/serverless/"}],"tags":[{"name":"serverless","slug":"serverless","permalink":"https://y0c.github.io/tags/serverless/"},{"name":"serverless-http","slug":"serverless-http","permalink":"https://y0c.github.io/tags/serverless-http/"},{"name":"koa","slug":"koa","permalink":"https://y0c.github.io/tags/koa/"}]},{"title":"React Component 생명주기","slug":"React-Component-생명주기","date":"2018-01-05T23:53:57.000Z","updated":"2018-09-09T13:47:47.574Z","comments":true,"path":"2018/01/06/React-Component-생명주기/","link":"","permalink":"https://y0c.github.io/2018/01/06/React-Component-생명주기/","excerpt":"","text":"목차 Component LifeCycle - Mounting Component LifeCycle - Updating Component LifeCycle - Unmounting Web Service, Mobile App 또는 다른 Application을 개발해봤다면 생명주기 라는말을 한 번쯤 들어보았을 것이다. 혹시 들어보지 못했더라도 전혀 상관없다!생명주기란 Application 이 시작, 실행, 활성, 비활성, 정지, 종료 등 일련의 상태를 순환하는데 이것을 생명주기라고 한다. React 에서도 마찬가지로 Component가 생성, 수정, 소멸 크게 3가지 부분으로 나뉘어서 LifeCycle API 가 제공되고 있는데. 이것들을 기억해두셨다가 개발도중에 필요할때 적절하게 구현해놓고 사용하면 된다. Component LifeCycle - Mounting 컴포넌트가 생성될때 호출되는 LifeCycle API 이다.생성자 메소드의 경우 ES6를 사용하지 않는다면 getInitialState 메소드를 사용하실 수 있고 더 자세한 내용은 React 공식문서 React Without ES6 를 참고하도록 하자. Component LifeCycle - Updating 컴포넌트가 생성될때 호출되는 LifeCycle API 이다.여기서 shouldComponentUpdate 메소드는 중요한 역활을 한다.이 메소드에서 변경된 props와 state를 통해 리렌더링을 할지 여부를 결정하게 되는데 기본적으로 true를 리턴하게 되있는데 false를 리턴할경우 렌더링을 하지 않는다. 123shouldComponentUpdate( nextProps, nextState ) &#123; return nextProps.list !== this.props.list&#125; 위 코드는 shouldComponentUpdate를 통해 이전 props와 변경될 props를 비교해서 렌더링 여부를 결정하는 예시이다. 여기서 기억해두어야할 점은 React에서는deep checking이나 JSON.stringfiy() 메소드를 통한 비교는 권장하지 않는다는 것이다.이는 비효율적이고 성능에 영향을 끼치기 때문에 일반적으로 shallow checking을 사용하고 있다. deep checking , shallow checking, immutable fashion 에 관해서는 다른 글을 통해서 더 자세히 다뤄볼 수 있도록 준비할 예정이다. React.PureComponent를 상속받게되면 props와 state에 대해 shallow compare로직이 들어가 있어서 좀 더 편리하게 사용할 수 있다고 한다.하지만 무분별하게 PureComponent를 상속받아서 사용한다면 오히려 성능저하를 야기할 수 있고 적절히 필요한곳에 shouldComponentUpdate를 구현하여 사용하시는 것이 좋은 방법이라고 생각된다. 그리고 설사 shouldComponentUpdate를 구현하지 않아서 무조건 true를 리턴하는 상황이 있다고 하더라도 React는 모든경우에 리렌더링을 하지는 않는다. shouldComponentUpdate를 통해 true를 리턴하게 되면 기존 Vitural DOM과 변경된 props나 state를 통해 만들어질 Vitural DOM과 비교하여 변경된 내용이 없다면 리렌더링을 하지 않는다. 하지만 규모가 커질수록 큰 성능 차이를 낼 수 있기 때문에 최적화 하는 습관을 들여놓는게 좋다고 생각한다. Component LifeCycle - Unmounting 컴포넌트가 소멸될시 호출되는 LifeCycle API입니다.위 설명과 같이 타이머 제거, 네트워크 요청취소, 이벤트 리스너 제거등에 주로 사용된다. 개인 공부용으로 쓴 글이라 혹시 잘못된 정보가 있다면 댓글로 알려주시면 수정하도록하겠습니다.","categories":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/categories/React/"}],"tags":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/tags/React/"}]},{"title":"React Event Handling","slug":"React-Event-Handling","date":"2018-01-03T14:30:05.000Z","updated":"2018-09-09T13:47:47.579Z","comments":true,"path":"2018/01/03/React-Event-Handling/","link":"","permalink":"https://y0c.github.io/2018/01/03/React-Event-Handling/","excerpt":"","text":"목차 React 와 일반적인 DOM element 에서 이벤트 핸들링의 차이 React에서 Event를 바인딩하는 여러가지 방법 SyntheticEvent React 와 일반적인 DOM element 에서 이벤트 핸들링의 차이React에서 이벤트를 핸들링하는 방법은 DOM elements의 이벤트를 핸들링 하는 방법과 매우 유사하다. 아래 가장 기본적인 예시를 보도록 하자.먼저 일반적인 DOM Element의 바인딩 하는 방법이다.123&lt;button onclick=\"activeLasers()\"&gt; Activate Lasers&lt;/button&gt; 위와 같이 표현할 수 있다. 같은 역활을 하는 Element를 React Way로 표현하면 다음과 같다.123&lt;button onClick=&#123;this.activeLaser&#125;&gt; Activate Lasers&lt;/button&gt; 첫 번째 차이점은 React에서는 Event를 CamelCase를 사용하여 표기한다는 점이다.두번째로 일반적인 DOM에서 이벤트를 바인딩 할 때에는 function을 직접 호출하지만 React는 이벤트를 직접 호출하지않고 function을 지정해주기만 한다.(즉 function 의 포인터 만 넘겨주고 직접 핸들링하지 않는다.) return false; 에 관해DOM element에 이벤트를 바인딩 한 경험이 있다면 return false; 를 많이 사용해봤을 것이다. 이 return false;의 역활은 브라우저의 기본동작을 막아주도록 동작한다.즉 event.preventDefault와 같은 역활을 한다고 볼 수 있다. 같은 syntax 를 jQuery event handler 안에서 사용할 경우event.preventdefault() 와 event.stopPropagation()을 동시에 처리해준다. 하지만 React의 경우 return false와 같은 syntax는 아무 동작을 하지 않는다.반드시 기본동작이나 버블링을 제어할 시에는 명시적으로 event.preventDefault()event.stopPropagation()을 작성해주어야 한다. React 에서 Event를 바인딩하는 여러가지 방법에 관하여Event Handler 에서 thisES6 Class syntax를 사용하여 React Component를 작성한 경우 event handler에서 this는 undefined가 된다. 왜냐하면 javascript에서 this는 호출한 context에 의해 결정되기 때문이다.만약 잘 이해가 가지 않는다면 아래 문서를 참고하도록 하자. this - JavaScript | MDN 이러한 this 에 관한 이슈로 인해 this를 이벤트 핸들러가 아닌 클래스에 바인딩 할 수 있는 몇가지 방법을 소개해볼까한다. 1. React.createClassReact 의 createClass 메소드를 사용하여 컴포넌트를 제작할경우 react는 모든 함수를 this에 자동으로 바인딩한다.즉 따로 바인딩 할 필요가 없지만 React.createClass syntax는 조만간 이후 버전의 릴리즈에서 추출 될 수 있으므로 지양하는 것이 좋다. 2. Rendering 시 바인딩1onChange=&#123;this.handleChange.bind(this)&#125; 위와 같이 렌더링시에 바로 this에 바인딩 해주는 방법도 있는데 이는 렌더링이 실행될때마다 새로운 함수를 만들어주기 때문에 퍼포먼스에 좋지 않다고 한다. 3. Constructor를 통한 바인딩1234constructor(props) &#123; super(props); this.handleChange = this.handleChange.bind(this);&#125; 생성자 함수에서 함수를 바인딩해주는 방법이다. 생성자 호출 될시 한번만 바인딩 되므로 퍼포먼스 이슈가 없고 React에서 권장하는 가장 일반적인 방법인데이벤트 핸들러가 많아지면 바인딩을 못한 휴먼에러가 생길 수 있고 매 번 바인딩을 하는 것은 꽤나 부담스럽고 귀찮은 작업이 될 수도 있다. 4. Class Property 의 Arrow Function 을 통한 바인딩123handleChange = () =&gt; &#123;&#125; 위와 같은 방법은 가장 심플하게 함수를 클래스에 바인딩 할 수 있는 방법을 제공하는데해당 syntax를 사용하기 위해서는 babel state-2 혹은 transfrom-class-properties 가 추가되있어야 정상적으로 동작한다. 참고123456789101112131415161718192021222324class Bork &#123; //Property initializer syntax instanceProperty = \"bork\"; boundFunction = () =&gt; &#123; return this.instanceProperty; &#125; //Static class properties static staticProperty = \"babelIsCool\"; static staticFunction = function() &#123; return Bork.staticProperty; &#125; &#125; let myBork = new Bork; //Property initializers are not on the prototype. console.log(myBork.__proto__.boundFunction); // &gt; undefined //Bound functions are bound to the class instance. console.log(myBork.boundFunction.call(undefined)); // &gt; \"bork\" //Static function exists on the class. console.log(Bork.staticFunction()); // &gt; \"babelIsCool\" 위 코드는 babel 공식문서에서 발췌한 코드이다.Class properties transform · Babel 코드에 있는 설명에는 Property initializer 를 통한 Arrow Function은 Prototype에 추가되지 않는다. 즉, Prototype 에 추가되지 않는 다는 의미는 클래스가 생성될때마다 메모리 공간을 차지하고 상속을 하지 못하는 문제점이 존재한다. 개인적인 생각으로는 이벤트 핸들러는 React Component 중에서도 주로 컨테이너 즉 Statefull Component 에 주로 바인딩 되고 props를 통해서 하위 컴포넌트로 핸들러를 전달한다. 컨테이너 특성상 자주 생성되지 않고 이벤트 핸들러는 일반적으로 상속이 자주 사용되지 않아서 단점보다 auto-binding을 통한 편리함과 장점이 크다고 생각하기 때문에 앞으로도 위와 같은 syntax를 자주 사용할 것 같다.저런 방법 마저 마음에 들지 않는다면 react-autobind, autobind-decorator 와 같은 라이브러리들이 있으니 참고하도록 하자. SyntheticEventReact 에서는 DOM 이벤트를 직접다루지 않고 이를 Wrapping한 SyntheticEvent를 사용한다. 이 SyntheticEvent 를 사용함으로써 브라우저마다 다른 event 객체에 대해 신경쓸 필요가 없다! 즉 크로스 브라우징에 관한 이슈가 해결된다.SyntheticEvent 에 관한 속성들은 따로 언급하진 않겠다.DOM 이벤트와 완벽하게 매칭되는게 아니므로 찾아볼 게 있을때는 React 공식문서를 참조하도록 하자.SyntheticEvent - React 개인 공부용으로 쓴 글이라 혹시 잘못된 정보가 있다면 댓글로 알려주시면 수정하도록하겠습니다.","categories":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/categories/React/"}],"tags":[{"name":"React","slug":"React","permalink":"https://y0c.github.io/tags/React/"},{"name":"Event Handling","slug":"Event-Handling","permalink":"https://y0c.github.io/tags/Event-Handling/"}]}]}